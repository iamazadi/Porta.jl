<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reaction Wheel Unicycle · Porta.jl</title><meta name="title" content="Reaction Wheel Unicycle · Porta.jl"/><meta property="og:title" content="Reaction Wheel Unicycle · Porta.jl"/><meta property="twitter:title" content="Reaction Wheel Unicycle · Porta.jl"/><meta name="description" content="How the reaction wheel unicycle works."/><meta property="og:description" content="How the reaction wheel unicycle works."/><meta property="twitter:description" content="How the reaction wheel unicycle works."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img class="docs-light-only" src="assets/logo.gif" alt="Porta.jl logo"/><img class="docs-dark-only" src="assets/logo-dark.png" alt="Porta.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">Porta.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li><a class="tocitem" href="hopffibration.html">Hopf Fibration</a></li><li><a class="tocitem" href="newsreport.html">News Report</a></li><li class="is-active"><a class="tocitem" href="reactionwheelunicycle.html">Reaction Wheel Unicycle</a><ul class="internal"><li><a class="tocitem" href="#The-Control-of-the-Balancing-Unicycle"><span>The Control of the Balancing Unicycle</span></a></li><li><a class="tocitem" href="#The-Z-Euler-Angle-Is-Not-Observable"><span>The Z-Euler Angle Is Not Observable</span></a></li><li><a class="tocitem" href="#Estimating-Tilt-Using-Accelerometers"><span>Estimating Tilt Using Accelerometers</span></a></li><li><a class="tocitem" href="#Stepping-Through-the-Implementation"><span>Stepping Through the Implementation</span></a></li><li><a class="tocitem" href="#Step-Forward"><span>Step Forward</span></a></li><li><a class="tocitem" href="#Update-Control-Policy"><span>Update Control Policy</span></a></li><li><a class="tocitem" href="#The-Convergence-of-Selected-Algebraic-Riccati-Equation-Solution-Parameters"><span>The Convergence of Selected Algebraic Riccati Equation Solution Parameters</span></a></li><li><a class="tocitem" href="#The-Controllability-of-the-Z-Euler-Angle"><span>The Controllability of the Z-Euler Angle</span></a></li><li><a class="tocitem" href="#Nonholonomic-Motion-Planning"><span>Nonholonomic Motion Planning</span></a></li><li><a class="tocitem" href="#Steering-Using-Sinusoids"><span>Steering Using Sinusoids</span></a></li><li><a class="tocitem" href="#Steering-Second-Order-Canonical-Systems"><span>Steering Second-Order Canonical Systems</span></a></li><li><a class="tocitem" href="#Attitude-Control-of-A-Space-Platform-/-Manipulator-System-Using-Internal-Motion"><span>Attitude Control of A Space Platform / Manipulator System Using Internal Motion</span></a></li><li><a class="tocitem" href="#Fiber-Optic-Gyroscopes"><span>Fiber Optic Gyroscopes</span></a></li><li><a class="tocitem" href="#Resources"><span>Resources</span></a></li></ul></li><li><a class="tocitem" href="multivariablecalculus.html">Multivariable Calculus</a></li><li><a class="tocitem" href="maxwellfield_persian.html">The Maxwell Field (Persian)</a></li><li><a class="tocitem" href="reactionwheelunicycle_persian.html">The Unicycle (Persian)</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="reactionwheelunicycle.html">Reaction Wheel Unicycle</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="reactionwheelunicycle.html">Reaction Wheel Unicycle</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/iamazadi/Porta.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/iamazadi/Porta.jl/blob/master/docs/src/reactionwheelunicycle.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-the-Reaction-Wheel-Unicycle-Works"><a class="docs-heading-anchor" href="#How-the-Reaction-Wheel-Unicycle-Works">How the Reaction-Wheel Unicycle Works</a><a id="How-the-Reaction-Wheel-Unicycle-Works-1"></a><a class="docs-heading-anchor-permalink" href="#How-the-Reaction-Wheel-Unicycle-Works" title="Permalink"></a></h1><p><img src="assets/reactionwheelunicycle/gravity_vector_estimation_upright.png" alt="gravity_vector_estimation_upright"/></p><p>This is a model of a unicycle with two symmetrically attached rotors. One of the reasons the matrix of inertia is not trivial is that the rotors’ axes of rotation do not intersect at a point. The constraint on the system is conservation of angular momentum. The angular velocity of the body is related to the rotor velocities. That relation gives rise to a differential equation in the rotation group Special Orthogonal of real dimension 3 for the robot’s body. Using the Euler parameters of <span>$SO(3)$</span> we obtain a local coordinate description of the differential equation, in terms of the roll, pitch and yaw angles. The robot can be repositioned by controlling the rotor velocities. The Linear Quadratic Regulator regulates the roll and pitch angles by a choice of a suitable input.</p><h2 id="The-Control-of-the-Balancing-Unicycle"><a class="docs-heading-anchor" href="#The-Control-of-the-Balancing-Unicycle">The Control of the Balancing Unicycle</a><a id="The-Control-of-the-Balancing-Unicycle-1"></a><a class="docs-heading-anchor-permalink" href="#The-Control-of-the-Balancing-Unicycle" title="Permalink"></a></h2><p>Here we deal with non-linear control systems that are described in terms of either differential equations or difference equations. In other words we consider the follwoing two types:</p><ol><li><p>Differential equations: <span>$\left\{ \begin{array}{l} \dot{x}(t) = f(x(t), u(t)) &amp;\\ y(t) = h(x(t), u(t)) \end{array} \right.$</span></p></li><li><p>Difference equations: <span>$\left\{ \begin{array}{l} x(k + 1) = f(x(k), u(k)) &amp;\\ y(k) = h(x(k), u(k)) \end{array} \right.$</span></p></li></ol><p>The variable <span>$x$</span> denotes the system state, the variable <span>$u$</span> denotes the control input to the system, and finally, the <span>$y$</span> variable denotes the output of the system. In the following, we explain how the system works through a robotics application. In this section, we see how the system works. But in the next section, we build a regulator to control the system state by generating suitable inputs for a given time frame.</p><p>The policy function produces the control inputs <span>$u(t)$</span> (or <span>$u(k)$</span> in the descrete case). The feeadback policy is called optimal control whenever it makes the system state <span>$x$</span> approximately equal to zero as the result of its application. The feeback policy is able to adapt through periodic policy updates. Between each two consecutive policy updates, a recursive relation updates filter coefficients, blocks of which are used to update the policy function. The policy update loop is slower whereas the filter coefficients update loop is faster.</p><p>The function <span>$h$</span>, which produces the output <span>$y$</span>, and the quality <span>$Q(x, u)$</span> are similar functions. The similarity of <span>$h(x, u)$</span> and the quality function <span>$Q(x, u)$</span> is first because both have the same parameter signature that includes the statem state vector <span>$x$</span> and the input vector <span>$u$</span>. Second, because both <span>$h$</span> and <span>$Q$</span> produce verifiable statements about the value of the ststem state at the next time step <span>$k + 1$</span> or <span>$t$</span> in the immediate future. Later in the next section, we see how a least squares relation can be used to calculate a difference equation between the desired state and the measured state, as a feedback signal for enhancing the quality function <span>$Q$</span> and producing accurate outputs <span>$y$</span> over time.</p><p>On one hand, the filter coefficients play the role of a critic that evaluates the quality of being in state <span>$x$</span> and having taken input <span>$u$</span>. On the other hand, the policy plays the role of an actor that uses the system state <span>$x$</span> as input to a matrix-vector product that produces the feedback policy <span>$u$</span>. The Actor/Critic architechture uses the first principles of reinforcement learning for adapting the optimal control inputs. The adpativeness of the controller increases the probability that the quality of the system state <span>$x$</span> is measured higher as the time variable <span>$t$</span> in differential equations (or <span>$k$</span> in the case of difference equations) progresses forward in time.</p><p><img src="assets/reactionwheelunicycle/system_states_a.png" alt="system_states_a"/></p><p>System states in real time. Even though the matrix of inertia (among other physical parameters) is unknown, the adaptive controller based on value iteration keeps the states stable and regulates them to zero.</p><p><img src="assets/reactionwheelunicycle/system_states_b.png" alt="system_states_b"/></p><h3 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h3><p>The robot that we build here is a self-balancing reaction wheel unicycle. As it is known from the name, this robot has only one wheel and therefore has one contact point with the ground surface. Just one contact point is the reason it is more complex compared to two-wheel balance robots. In fact, the robot has to preserve it balance in two directions around two perpendicular axes. In this robot, the motion in the forward/backward direction is like balancing a two-wheel balance robots, and so it obeys the same laws of physics. But since the robot has no way of moving to either left or right, in order to balance along the left/right direction we have to use another torque generator. For that purpose, we use a rotating mass, which is also called a reaction wheel. This rotating mass, which is mounted at the top of the robot, works based on the physical principle that if we apply a torque on it until it starts moving, then that mass also applies a torque on the robot&#39;s chassis, as large as the torque that is applied to it. One of the physical principles called the preservation of angular momentum explains this phenomenon. According to this principle, the sum of the angular momenta of a rotating set around a specific axis remains constant, unless it is acted upon by an external torque. So if one of the parts of the rotating set starts rotating using its internal torque, then the complement of the part (the other parts of the set) start rotating in the opposite direction in order to neutralize the internal motion of that part. Otherwise the angular momentum of the entire set will not be preserved. Using this reaction torque we can take control of the angle of the robot&#39;s bofy in the left and right directions.</p><p>The one-wheel balance robot may not seem so practical at first, but similar to two-wheel balance robots, or different kinds of the inverted pendulum, provides proper conditions for experimenting with various control algorithms. In addition, the most important part of the robot, the reaction wheel has a special application in satellites. After a satellite is placed into orbit around a celestial body, the only force acting on it is caused by the gravitational field. Therefore, it will have no control over its own motion. In order for the satellite to make small maneuvres along its path, or to be able to make small adjustments to its orbit, usually they equip it with three motion systems: the propulsion motor, the electromagnetic torque generator, or the reaction wheel. The first item is outside of the scope of this project. The reaction wheel is applied in satellites by rotating the wheel in the opposite direction for as much as needed for pointing at a specific direction. The amount of rotation is determined based on the ratio of the rotational momenta between the satellite and the wheel. To control the rotation of the satellite in all spatial directions, it is equipped with three wheels that are mounted in mutually perpendicular directions. Professional motorcyclists also take advantage of this property of the preservation of rotational inertia. Whenever a motorcyclist makes a jump and is detatched from the Earth, The only force acting on in that moment is the gravity of the Earth, which is outside of the control of the cyclist. In this situation, the cyclist can set its landing angle (attack vector) by accelerating the rear wheel or decelerating (braking). The effect of the reaction of the rear wheel that is applied to the body of the motorcycle, rotates the whole system in the upward or downward direction. To build this robot, it is required to become familiar with the mechanical structure, mathematical modelling, control algorithms, digital design and electronic circuits.</p><h2 id="The-Z-Euler-Angle-Is-Not-Observable"><a class="docs-heading-anchor" href="#The-Z-Euler-Angle-Is-Not-Observable">The Z-Euler Angle Is Not Observable</a><a id="The-Z-Euler-Angle-Is-Not-Observable-1"></a><a class="docs-heading-anchor-permalink" href="#The-Z-Euler-Angle-Is-Not-Observable" title="Permalink"></a></h2><p>The control and navigation of mobile robots is not pissible without knowing the position. For positioning, various sensors have been designed and built, which are used based on their specific applications. Among positioning systems one can name a list: accurate accelerometrs used in rockets, existing gyroscopes in flying machines, altimeters, navigation systems based on the magnetic field of the Earth, or even more advanced navigation systems based on the images of stars that are used in satellites and spacecrafts.</p><p><img src="assets/reactionwheelunicycle/mpu6050_far.JPG" alt="mpu6050 far"/></p><p>Nowadays, the electromechanical sensors are manufactured in small scales (micrometers). This technology is known by the name of Micro-Electro-Mechanical Systems (MEMS). The birth of the MEMS technology has had a great effect on the price, size and the improved precision of different kinds of electronic sensors in the market. This subject makes it possible to use a multiple of such sensors in a small robot. In some cases, manufacturers offer multiple sensors of different types in a unit microchip package.</p><p><img src="assets/reactionwheelunicycle/mpu6050_near.JPG" alt="mpu6050 near"/></p><p>Among positioning peripherals, sensors that measure the acceleration, the rotational velocity (gyroscopes), and the magnetic field are the most applicable in small self-driving robots. This section focuses on the accelerometer and the gyroscope sensors. Using accelerometers you can calculate the accleration of your robot, along with its velocity and position through integration. You should know that the gravitational field of the Earth has an effect on the measurements of an accelerometer. This issue makes it harder to find the position, but it is useful for measuring the deviation from the gravitational direction (the vertical line). Also, the gyroscope essentially measures the angular velocity, after which it will be possible to calculate the angular position (direction) using integration. This way, with the help of accelerometrs and gyroscopes you have the ability to measure the position and orientation of the motion of your robot, and in particular the estimate of the angle of deviation from the vertical line (the direction of gravity) is possible.</p><h3 id="Acclerometers"><a class="docs-heading-anchor" href="#Acclerometers">Acclerometers</a><a id="Acclerometers-1"></a><a class="docs-heading-anchor-permalink" href="#Acclerometers" title="Permalink"></a></h3><p>Every accelerometer based on Micro Electro Mechanical Systems (MEMS) has some sort of moving part inside of it, such that it moves under the influence of external forces. This part is held in place using a spring structure, and the displacement caused by the external force on it, is measured using various methods such as the change in capacitance. The Hooke&#39;s law states that the force excerted by a spring is directly proportional to the displacement caused by that force. Then, knowing the spring constant (the force per unit of distance traveled) and the mass of the part, this displacement is transformed to its equivalent acceleration. Therefore, MEMS accelerometers measure an external force excerted on the moving part. That is why these accelerometers measure the static acceleration (the Earth&#39;s gravity) and the dynamical acceleration (due to changes in velocity) the same and decomposing the two measurements is your responsibility. In this way, if the direction of the accelerometer is in the direction of the Earth&#39;s gravitational field, then the measurement value is the representation of the acceleration due to motion in addition to the gravitational acceleration (<span>$9.8 \frac{m}{s^2}$</span>). And if the direction of the measurement of the sensor is in the horizontal direction (perpendicular to the gravitational field of the Earth) then only the dynamical acceleration is measured and gravity will not have any effect on the measurement. So, in case a one-axis accelerometer (capable of measuring in one of the directions of the coordinate system) is used in a system, the orientation of it must be specified with respect to the gravitational direction so that the static acceleration is computable.</p><p><img src="assets/reactionwheelunicycle/two_axis_accelerometer.jpeg" alt="two_axis_accelerometer"/></p><p>Using a two-axis accelerometer for measuring the direction of the Earth&#39;s gravity in the plane perpendicular to the Earth. In this figure, the orientation of the two-axis accelerometer (X-Y) with respect to the horizontal direction is computable using the given relation.</p><p><span>$\alpha = tan^{-1}(\frac{A_X}{A_Y})$</span></p><p>Now, imagine that you have two or three accelerometers such that their directions of measurement are mutually orthogonal (like the X, Y, and Z coordinate axes of the standard Cartesian coordinate system). If the velocity of this set is constant and only the static accelration due to gravity acts on it, by comparing the ratio of the measured accelerations across the axes, the orientation angle of the set with respect to the direction of gravity is computable. This is the way that many electronic balances and mobile robots use to measure the angle of orientation with respect to the direction of gravity.</p><p><img src="assets/reactionwheelunicycle/tri_axis_accelerometer.jpeg" alt="tri_axis_accelerometer"/></p><p>Using a tri-axis accelerometer for measuring the direction of the Earth&#39;s gravity in the three-dimensional space. In this figure, the orientation of the three-axis accelerometer (X-Y-Z) with respect to the hirozontal plane and the direction of gravity is computable using the given relations.</p><p><span>$\alpha = tan^{-1}(\frac{A_{X,OUT}}{\sqrt{A^2_{Y,OUT} + A^2_{Z,OUT}}})$</span></p><p><span>$\beta = tan^{-1}(\frac{A_{Y,OUT}}{\sqrt{A^2_{X,OUT} + A^2_{Z,OUT}}})$</span></p><p><span>$\gamma = tan^{-1}(\frac{\sqrt{A^2_{X,OUT} + A^2_{Y,OUT}}}{A_{Z,OUT}})$</span></p><p>Note that knowing the angles between each axis and the direction of gravity, does not give the general angular orientation of the accelerometer in the three-dimensional space. In fact, if this accelerometer is rotated about an axis parallel to gravity, all three axes will measure the same result compared to before the rotation. The reason for the Z-Euler angle not being observable is that the projection of the gravity vector onto the horizontal plane looks like a point (approximately the zero vector). In order to determine the angular orientation of the accelerometer in a complete way, it needs to measure at least two known vectors that are not parallel with respect to each other (the gravity vector and another vector). In every case, using a three-axis accelerometer one can build an electronic balance that can measure tilt in two mutually perpendicular directions.</p><p>Many manufacturers, make two-axis and tri-axis accelerometers as one chip, where two and three accelerometers (respectively) are placed in perpendicular directions in a unit package.</p><p>One of the fundamental problems of using accelerometrs to measure deviation, is the effect of dynamical accelerations (caused by changes in velocity) on the measurement of direction. For example, if you install such a device on a car and want to measure the slope of the road, the measured direction is correct as long as the vehicle has constant velocity. But when the car&#39;s velocity changes, the vector of dynamical acceleration is added to the vector of static acceleration and your measuring device measures the direction of this new vector (which is different from the direction of the Earth&#39;s gravity). One other disadvantage of accelerometers is the sensitivity to vibrations and the production of noisy results.</p><p><img src="assets/reactionwheelunicycle/estimating_the_road_slope.jpeg" alt="estimating_the_road_slope"/></p><p>Estimating the slope of the road through measuring the direction of gravity using the accelerometer that is embedded in the car. In (a) the car has positive acceleration (increasing velocity), and in (b) without acceleration (constant velocity), and in (c) the car has negative acceleration (braking). As you can see, only in the figure (b) the direction of gravitational acceleration and the slope of the road are measured correctly.</p><p>Sensitivity to vibrations and dependence on dynamical accelerations, make it necessary to get help from other sensors such as gyroscopes and the magnetic field sensor (the electronic compass) for measuring the direction of the Earth&#39;s gravity.</p><p>To choose an accelerometer, one should pay attention to the measurement range, the sampling rate, the interface (the analog or digital communication protocol) and also the number of axes that are needed in the project (the number dimensions). Other parameters that should be considered in MEMS accelerometers are sensitivity to temperature and supply voltage changes, and the existence of an initial offset (the value read at zero acceleration), which is corrected with calbration. Here, we show how to use three-axis accelerometers.</p><h3 id="Gyroscopes"><a class="docs-heading-anchor" href="#Gyroscopes">Gyroscopes</a><a id="Gyroscopes-1"></a><a class="docs-heading-anchor-permalink" href="#Gyroscopes" title="Permalink"></a></h3><p>As you know, a gyroscope essentially measures the angular velocity about an axis. A rotation about an axis is measured with a specific value (often in terms of degrees per second <span>$\frac{deg}{s}$</span>) and a rotation in the opposite direction results in a value with the opposite sign, and in the case where the rotation is stopped, the value of zero is measured. Mechanical gyroscopes that work based on coriolis forces / the coriolis effect of a rotating mass, had been used in airplanes and rockets for a while until optical gyroscopes and various kinds of MEMS were built. Among gyroscopes, optical gyroscopes are the most accurate, whereas the MEMS gyroscopes are the cheapest and the most applied type of this measuring device.</p><p>Unlike accelerometers, a gyroscope is not generally sensitive to vibrations and produces more continuous measurement results. But, since the angular velocity is not that useful on its own, and the angular orientation is more useful to mobile vehicles, the output of this sensor is integrated to extract the angular position. Having an integrator in a positioning system based on gyroscopes causes the accumulation of the smallest offsets and unavoidable permanent errors over time to produce greater errors. As such, the angular position computed by  the integrator using the output of the gyroscope drifts away from the real value over time, so much that after the passgae of a few minutes (or even a few seconds) the computed values are no longer valid. This issue forces the use of other sensors such as a detector of the Earth&#39;s magnetic field or an acclerometer along with the gyroscope, unless the goal of measurement is only the angular velocity and not the angular position, in which case the integrator is removed and the output of the gyroscope will be accurate enough.</p><p>Like MESMS accelerometers, MEMS gyroscopes are manufactured in small sizes with afforable prices, and many manufacturers provide two or three gyroscopes in a single electronic package for measurements along different directions that are perpendicular with respect to one another.</p><p><img src="assets/reactionwheelunicycle/tri_axis_gyroscope.jpeg" alt="tri_axis_gyroscope"/></p><p>A three-axis gyroscope measures the angular velocity about three mutually perpenducular axes (X, Y and Z). Ususally, the right-handed rotation about each axis is denoted by the positive sign and the left-handed rotation is denoted by the negative sign. The angular velocity is expressed in terms of degrees per second <span>$\frac{deg}{s}$</span>. In flying vehicles such as rockets and airplanes and also some mobile robots, the names Roll, Yaw and Pitch are used to label the rotation axes. The axes Roll, Yaw and Pitch are not necessarily aligned with the X, Y and Z axes and this fact depends on the assignment of the coordinate system axes to the mobile object.</p><p>When choosing a gyroscope, one should consider its measurable velocity range, the sampling rate, the way to communicate with it (analog or digital), and also the number of required axes in the project (the number of dimensions). In addition to those parameters, consider issues such as the sensitivity to temperature and supply voltage changes, the initial offset (the value read in the stationary state) and the cross-sxis sensitivity. If a gyroscope is rotated around an axis perpendicular to the measurement axis, it should measure the value zero, but it is not the case in practice. The gyroscope can show sensitivity to rotation in directions other than the one that is to be measured. This value, which must be as small as possible, represents the cross-axis sensitivity and is expressed in terms of the error percentage.</p><h3 id="Fusing-the-Output-Data-of-Accelerometers-with-that-of-Gyroscopes"><a class="docs-heading-anchor" href="#Fusing-the-Output-Data-of-Accelerometers-with-that-of-Gyroscopes">Fusing the Output Data of Accelerometers with that of Gyroscopes</a><a id="Fusing-the-Output-Data-of-Accelerometers-with-that-of-Gyroscopes-1"></a><a class="docs-heading-anchor-permalink" href="#Fusing-the-Output-Data-of-Accelerometers-with-that-of-Gyroscopes" title="Permalink"></a></h3><p>In this section we want to use the data of both accelerometers and gyroscopes in order to estimate the correct direction of gravity. A tri-axis accelerometer alone can be used to find the orientation with respect to the gravity vector. However, this estimate is correct only when there are no accelerations acting on the system other than the static gravitational acceleration. This is not possible in mobile robots. On top of that, an accelerometer is very sensitive to vibrations and due to too much noise, its output does not have much value on its own. In contrast, gyroscopes have their own disadvantages, the most important of which is the gradual drifting of the calculated angle from the real value, which is calculated using integration over time. Fortunately, the errors existing in acclerometers and gyroscopes are completely different in nature, such that by using the sensors in the proper way, one can correct both errors. For an effective application of the two sensors, one must fuse their data together in a way that the fused result is more valid than the result of each sensor on its own.</p><p>Assuming that there are no long-term dynamical accelerations acting on the system, and so assuming that the direction of gravity has been calculated in a correct way, you can subtract the gravity vector of the Earth (the direction of which is known and its magnitude is approximately equal to <span>$9.8 \frac{m}{s^2}$</span>) from the filtered information of the accelerometer to get the dynamical acceleration of the motion. By integrating the dynamical acceleration you can calculate the velocity of motion and the position of the robot. But these results are valid short-term because of the integral operation. To prevent the accumulation of error over a long period of time, it is necessary to add another positioning sensor such as the Global Positioning System (GPS) to the set.</p><p><img src="assets/reactionwheelunicycle/sensor_fusion.jpeg" alt="sensor_fusion"/></p><p>As you know, in a positioning system including tri-axis gyroscopes and accelerometers (having six degrees of freedom), the gravity vector calculated using the accelerometer is like a yardstick that counteracts the effect of the gradual drift of the gyroscope from the estimation of the direction of gravity. But this vector does not have any projections on the horizontal plane. In addition, knowing the direction and magnitude of a known vector (like the gravity vector) in an orthogonal coordinate system, it is not possible to determine the direction of all three coordinate axes at the same time. In fact, one can show that there are an infinite number of coordinate systems that measure a particular vector the same (if you rotate a coordinate system about an axis parallel to that particular vector, all coordinate systems that are created as a result of rotating the coordinate system through various angles about the axis, measure the said vector the same). To detect the orientation of a coordinate system in the three-dimensional space, we have to have the measurement results of a pair of non-parallel vectors in the coordinate system. The coordinate system that we want to find the orientation of, is our Inertial Measurement Unit (IMU). That is why the output of a data fusion algorithm that uses the information of tri-axis accelerometers and gyroscopes, is not a valid source to find the orientation around the vertical axis (the Z-axis). To solve this problem one must use another vector that has a substantial projection on the horizontal plane. An electronic compass can accomplish this goal. Positioning systems in flying machines generally take advantage of all three sensors: compasses, gyroscopes and accelerometers (having nine degrees of freedom), and the fusion algorithms in them process the information of all of the sensors.</p><h2 id="Estimating-Tilt-Using-Accelerometers"><a class="docs-heading-anchor" href="#Estimating-Tilt-Using-Accelerometers">Estimating Tilt Using Accelerometers</a><a id="Estimating-Tilt-Using-Accelerometers-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-Tilt-Using-Accelerometers" title="Permalink"></a></h2><p>In this section, we find an estimator for the roll and pitch angles of a rigid body that has only rotational degrees of freedom. This estimate is based on the measurements of multiple accelerometers that are mounted on the rigid body, such that it is assumed that we know their mounting positions and their directions of orientation. First, we describe the roblem setup in a formal way. Then, we find an estimate of the gravity vector in the frame of the robot. Finally, we use the gravity vector in order to calculate the roll and pitch angles. In this section, we follow the setup described in Sebastian Trimpe and Raffaello D’Andrea (2010) [2].</p><h3 id="The-Problem-Setup"><a class="docs-heading-anchor" href="#The-Problem-Setup">The Problem Setup</a><a id="The-Problem-Setup-1"></a><a class="docs-heading-anchor-permalink" href="#The-Problem-Setup" title="Permalink"></a></h3><p>Suppose there is a rigid body that is standing on a fixed pivot point without friction. Therefore, the body has three rotational degrees of freedom, but has no translational degrees of freedom. The origin of the coordinate system of the body, which is denoted by <span>$\hat{B}$</span>, is at the center of rotation. The inertial reference frame is denoted by <span>$\hat{O}$</span>, the origin of which is coincident with the origin of the body&#39;s frame <span>$\hat{B}$</span>. On the body, there are <span>$L$</span> sensors that are mounted at specific locations <span>$p_i$</span>, for <span>$i = 1, ..., L$</span>. It is assumed that the position of sesnors <span>$^Bp_i$</span> is known in the reference frame of the body. Each sensor <span>$\hat{A}_i$</span> measures the local acceleration along three directions in its local frame. Two rotation matrices are introduced to describe the rotation of the rigid body and the mounting orientaton of the sensors: the first matrix describes the rotation of the inertial reference frame <span>$\hat{O}$</span> with respect to the body&#39;s frame <span>$\hat{B}$</span>, and the second matrix determines the rotation of the <span>$i$</span>th sensor&#39;s local reference frame with respect to the body&#39;s frame.</p><p><span>$\left\{ \begin{array}{l} ^{O}_{B}R &amp;\\ ^{A_i}_{B}R \end{array} \right.$</span></p><p>For example, a vector <span>$^Bv$</span> in the body&#39;s reference frame can be represented in the inertial reference frame with a matrix-vector multiplication <span>$^{O}v = ^{O}_{B}R \ ^{B}v$</span>.</p><p><img src="assets/reactionwheelunicycle/theproblemsetup.jpeg" alt="the_problem_setup"/></p><p>An accelerometer, measures <span>$^{A_i}m_i$</span> the acceleration vector <span>$^O\ddot{p}_i$</span> at its mounting position in addition to the gravity vector <span>$^Og$</span>, which is rotated with respect to its local frame <span>$\hat{A}_i$</span>.</p><p><span>$^{A_i}m_i = ^{A_i}_{B}R \ ^{B}_{O}R (^{O}\ddot{p}_i + ^{O}g) + ^{A_i}n_i$</span>  (Equation 1)</p><p>In equation 1, the measurement of the accelerometer is denoted by <span>$^{A_i}m_i \in \mathbb{R}^3$</span> and the measurement noise is denoted by <span>$^{A_i}n_i \in \mathbb{R}^3$</span>. It is assumed that it is the white noise, and its value <span>$\mathbb{E}[^{A}n_i \ (^{A}n_i)^T] = \sigma_n^2 I_3$</span> is limited by the zero mean <span>$\mathbb{E}[^{A}n_i] = 0$</span> and the standard deviation <span>$\sigma_n$</span>. Here, the mathematical expected value is denoted by <span>$\mathbb{E}$</span> and the matrix <span>$I_3 \in \mathbb{R}^{3 \times 3}$</span> is the identity matrix of real dimension three. This model of noise is reasonable for acclerometers that are based on the MEMS technology provided that the bias is subtracted from it.</p><p>Using the coordinate transformation <span>$^Op_i = ^O_BR ^Bp_i$</span> and the fact that <span>$^Bp_i$</span> is constant in time <span>$\frac{d \ ^{B}p_i}{dt} = 0$</span>, we arrive at the conclusion that the acceleration <span>$^O\ddot{p_i}$</span> in terms of the inertial reference frame <span>$\hat{O}$</span> is calculated using the second derivative of the rotation matrix <span>$^O_B\ddot{R}$</span> with respect to time <span>$\frac{d^2 \ ^{O}_{B}R}{dt^2} = ^{O}_{B}\ddot{R}$</span>. The matrix <span>$^O_B\ddot{R}$</span> captures the dynamic terms of the rigid body: the rotational and centripetal acceleration terms.</p><p><span>$^{O}\ddot{p}_i = ^{O}_{B}\ddot{R} \ ^{B}p_i$</span>  (Equation 2)</p><p>Using equation 2, one can rewrite the acceleration measurement in equation 1 as follows:</p><p><span>$^{A_i}m_i = ^{A_i}_{B}R \ ^{B}_{O}R (^{O}_{B}\ddot{R} \ ^{B}p_i + ^{O}g) + ^{A_i}n_i$</span>  (Equation 3)</p><p>Since all of the rotational orientations of the sensors, denoted by <span>$^{A_i}_BR$</span>, are assumed to be known, we can represent the sensor measurements <span>$^{A_i}m_i$</span> in terms of the body&#39;s frame of reference <span>$\hat{B}$</span> by multiplying equation 3 on the left with the transpose of the rotation matrix <span>$^B_{A_i}R = ^{A_i}_BR^T$</span>.</p><p><span>$^{B}m_i = \tilde{R} ^{B}p_i + ^{B}g + ^{B}n_i$</span>  (Equation 4)</p><p>In equation 4, the matrix <span>$\tilde{R}$</span> combines the rotation of the body <span>$^{B}_{O}R$</span> and the dynamic terms of the motion of the body <span>$^{O}_{B}\ddot{R}$</span> using a matrix-matrix product: <span>$\tilde{R} := ^{B}_{O}R \ ^{O}_{B}\ddot{R}$</span>.</p><p><span>$^{B}g = ^{B}_{O}R \ ^{O}g$</span>  (Equation 5)</p><p>Also in equation 4, the gravity vector <span>$^{B}g$</span> is represented in terms of the body&#39;s reference fame <span>$\hat{B}$</span>, and the noise vector <span>$^{B}n_i$</span> is rotated with respect to the body&#39;s frame <span>$^{B}n_i = ^{B}_{A_i}R \ ^{A_i}n_i$</span>. The mean of the noise after the coordinate transformation is still equal to zero <span>$\mathbb{E}[^{B}n_i] = 0$</span>, and the standard deviation of the noise is still limited to the scalar multiplication of <span>$\sigma_n^2$</span> with the three-dimensional identity matrix: <span>$\mathbb{E}[^{B}n_i (^{B}n_i)^T] = \sigma_n^2 I_3$</span>.</p><p>Suppose that the measurements are done at a rate <span>$T$</span> and the time index is introduced as <span>$k$</span>. So we can rewrite equation 4 like the following:</p><p><span>$^{B}m_i(k) = \tilde{R}(k) \ ^{B}p_i + ^{B}g(k) + ^{B}n_i(k)$</span>  (Equation 6)</p><p>With the given measurements that are done in equation 6 for every sensor from <span>$i$</span> through <span>$L$</span> at time <span>$k$</span>, the objective is to estimate the tilt of the rigid body at time <span>$k$</span>, which is captured by the matrix <span>$^B_OR$</span>. As an intermediate step, an estimate of the gravity vector <span>$^Bg(k)$</span> at time <span>$k$</span> (and as a side product) an estimate of the matrix <span>$\tilde{R}(k)$</span> is derived. Then, the estimate of the gravity vector is used to find the roll and pitch angles of the rigid body.</p><h3 id="The-Optimal-Estimation-of-the-Gravity-Vector"><a class="docs-heading-anchor" href="#The-Optimal-Estimation-of-the-Gravity-Vector">The Optimal Estimation of the Gravity Vector</a><a id="The-Optimal-Estimation-of-the-Gravity-Vector-1"></a><a class="docs-heading-anchor-permalink" href="#The-Optimal-Estimation-of-the-Gravity-Vector" title="Permalink"></a></h3><p>In this section, the problem of the estimation of the gravity vector <span>$^Bg$</span> in the reference frame of the robot&#39;s body <span>$\hat{B}$</span> using the acceleration measurements <span>$^Bm_i$</span> in equation 6, for <span>$i = 1, ..., L$</span>, is described as a least-squares problem. All of the measurements in equation 6, which are <span>$L$</span> in number, are combined in a matrix equation where the time index <span>$k$</span> is removed for convenience.</p><p><span>$M = QP + N$</span>  (Equation 7)</p><p>In equation 7, the matrix denoted by <span>$M$</span> combines the measurements of all sensors, <span>$Q$</span> denotes the matrix of unknown parameters, whereas <span>$P$</span> denotes the matrix of known parameters.</p><p><span>$M := \begin{bmatrix} ^{B}m_1 &amp; ^{B}m_2 &amp; \ldots &amp; ^{B}m_L \end{bmatrix} \in \mathbb{R}^{3 \times L}$</span>  (Equation 8)</p><p><span>$Q := \begin{bmatrix} ^{B}g &amp; \tilde{R} \end{bmatrix} \in \mathbb{R}^{3 \times 4}$</span>  (Equation 9)</p><p><span>$P := \begin{bmatrix} 1 &amp; 1 &amp; \ldots &amp; 1 \\ ^{B}p_1 &amp; ^{B}p_2 &amp; \ldots &amp; ^{B}p_L \end{bmatrix} \in \mathbb{R}^{4 \times L}$</span>  (Equation 10)</p><p><span>$N := \begin{bmatrix} ^{B}n_1 &amp; ^{B}n_2 &amp; \ldots &amp; ^{B}n_L \end{bmatrix} \in \mathbb{R}^{3 \times L}$</span></p><p>The letter <span>$N$</span> in equation 7 denotes the matrix that combines all of the noise vectors, meaning its expected value is equal to zero <span>$\mathbb{E}[N] = 0$</span>, and its standard deviation is limited by the scalar multiplication of the <span>$L$</span>-dimensional identity matrix <span>$I_L$</span> with <span>$\sigma_N^2 := \sqrt{3} \sigma_n$</span>:</p><p><span>$\mathbb{E}[N^T N] = 3\sigma_n^2 I_L = \sigma_N^2 I_L$</span>.</p><p>Other than the gravity vector <span>$^Bg$</span>, which is what we are after, the unknown parameters matrix <span>$Q$</span> also contains the matrix <span>$\tilde{R}$</span>, combining the rotation of the body <span>$^{B}_{O}R$</span> and the dynamic terms of the motion of the body <span>$^{O}_{B}\ddot{R}$</span>. In the follwoing, a scheme for the optimal estimation of the entire matrix <span>$Q$</span> is described, even though the gravity vector motivates the tilt estimation. In other applications, one might also be interested in estimating the dynamic terms, denoted by <span>$\ddot{R}$</span>, which is derived from the matrix <span>$\tilde{R} = ^{B}_{O}R \ ^{O}_{B}\ddot{R}$</span> once the rotation matrix <span>$^B_OR$</span> is found.</p><p>The objective is to find an estimate of the optimal matrix <span>$\hat{Q}^*$</span> of the unknown parameters matrix <span>$Q$</span> such that the expected value of the optimization error is minimized (see equation 11 where <span>$||.||_F$</span> denots the Frobenius matrix norm), subjected to the fact that <span>$\mathbb{E} [\hat{Q}] = Q$</span> the expected value of the matrix <span>$\hat{Q}^*$</span> equals the matrix <span>$Q$</span>.</p><p><span>$\underset{\hat{Q}}{min} \ \mathbb{E} \ [|| \hat{Q} - Q ||^2_F]$</span>  (Equation 11)</p><p>The estimate of the matrix <span>$\hat{Q}$</span> is restricted to linear combinations of the measurements <span>$M$</span>, that is, we look for an optimal matrix <span>$X^*$</span> so that we can decompose the matrix <span>$Q$</span> as a matrix-matrix product <span>$\hat{Q} = MX$</span>. This way results in a straight-forward implementation: at each time step, the estimate of the matrix <span>$Q$</span> is calculated by a matrix-matrix product. Note that in equation 7, the matrices <span>$M$</span>, <span>$Q$</span> and <span>$N$</span> are variable in time. At each time <span>$k$</span>, according to the measurements of the matrix <span>$M$</span>, we want to find an optimal estimate of the unknown parameters matrix <span>$Q$</span>. The next lemma, states the best unbiased linear estimate of the full parameter matrix <span>$Q$</span>.</p><h3 id="The-Full-Estimation-Lemma"><a class="docs-heading-anchor" href="#The-Full-Estimation-Lemma">The Full Estimation Lemma</a><a id="The-Full-Estimation-Lemma-1"></a><a class="docs-heading-anchor-permalink" href="#The-Full-Estimation-Lemma" title="Permalink"></a></h3><p>Given the real matrices <span>$P \in \mathbb{R}^{4 \times L}$</span> and <span>$M \in \mathbb{R}^{3 \times L}$</span> satisfying <span>$M = QP + N$</span> with unknown matrix <span>$Q \in \mathbb{R}^{3 \times 4}$</span> and the matrix random variable <span>$N \in \mathbb{R}^{3 \times L}$</span> with <span>$\mathbb{E}[N] = 0$</span>, <span>$\mathbb{E}[N^T N] = \sigma_N^2 I_L$</span>. Assuming <span>$P$</span> has full row rank, the (unique) minimizer <span>$X^* \in \mathbb{R}^{L \times 4}$</span> of</p><p><span>$\underset{X}{min} \ \mathbb{E} \ [||MX - Q||_F^2]$</span> subjected to <span>$\mathbb{E} \ [MX] = Q$</span> (Equation 12)</p><p>is given by</p><p><span>$X^* = P^T (PP^T)^{-1}$</span>.  (Equation 13)</p><p>The minimum estimation error is</p><p><span>$\mathbb{E} \ [|| MX^* - Q ||_F^2] = \sigma_N^2 \sum_{i = 1}^4 \frac{1}{s_i^2(P)}$</span>,  (Equation 14)</p><p>where <span>$s_i(P)$</span> denotes the <span>$i$</span>th largest singular value of <span>$P$</span>. </p><h3 id="The-Proof-of-the-Full-Estimation-Lemma"><a class="docs-heading-anchor" href="#The-Proof-of-the-Full-Estimation-Lemma">The Proof of the Full Estimation Lemma</a><a id="The-Proof-of-the-Full-Estimation-Lemma-1"></a><a class="docs-heading-anchor-permalink" href="#The-Proof-of-the-Full-Estimation-Lemma" title="Permalink"></a></h3><p>Since <span>$\mathbb{E}[MX] = \mathbb{E}[M]X = QPX$</span>, it is required that</p><p><span>$PX = I$</span>  (Equation 15)</p><p>to satisfy <span>$\mathbb{E}[MX] = Q$</span>. Next, consider the singular value decomposition (SVD) of <span>$P$</span>,</p><p><span>$P = U \begin{bmatrix} \Sigma &amp; 0 \end{bmatrix} \begin{bmatrix} V_1^T \\ V_2^T \end{bmatrix}$</span>,  (Equation 16)</p><p>with <span>$U \in \mathbb{R}^{4 \times 4}$</span> unitary, <span>$\Sigma \in \mathbb{R}^{4 \times 4}$</span> diagonal, <span>$V_1 \in \mathbb{R}^{L \times 4}$</span>, <span>$V_2 \in \mathbb{R}^{L \times (L - 4)}$</span>, and <span>$V = \begin{bmatrix} V_1 &amp; V_2 \end{bmatrix}$</span> unitary. From the full row rank assumption on <span>$P$</span>, it follows that <span>$\Sigma$</span> is positive definite. Therefore, a parameterization of all <span>$X$</span> that satisfy equation (15) is given by</p><p><span>$X = V_1 \Sigma^{-1}U^T + V_2 \bar{X}$</span>,  (Equation 17)</p><p>where <span>$\bar{X} \in \mathbb{R}^{(L - 4) \times 4}$</span> is a free parameter matrix. Thus, <span>$\bar{X}$</span> needs to be chosen such that equation (12) is minimized: Using equations (7), (15) and basic peoperties of the trace operation, yields</p><p><span>$\mathbb{E} \ [||MX - Q||_F^2] = \mathbb{E} \ [||NX||_F^2]$</span></p><p><span>$= \mathbb{E} \ [trace(X^T N^T N X)] = trace(\mathbb{E} \ [N^T N] X X^T)$</span></p><p><span>$= \sigma_N^2 \ trace(X X^T) = \sigma_N^2 \ trace(V^T X (V^T X)^T)$</span></p><p><span>$= \sigma_N^2 ||\begin{bmatrix} \Sigma^{-1} U^T \\ \bar{X} \end{bmatrix}||_F^2$</span>,  (Equation 18)</p><p>which is minimized by <span>$\bar{X} = 0$</span>. Therefore,</p><p><span>$X^* = V_1 \Sigma^{-1} U^T = P^T (P P^T)^{-1}$</span>,</p><p>which can readily be seen by inserting equation (16) for <span>$P$</span>, and</p><p><span>$\mathbb{E}[||MX^* - Q||_F^2] = \sigma_N^2 ||\Sigma^{-1} U^T||_F^2 = \sigma_N^2 ||\Sigma^{-1}||_F^2$</span>.</p><p><span>$\square$</span></p><p>The optimal estimate <span>$\hat{Q} = MX^*$</span> includes both the optimal estimate of the gravity vector <span>$^Bg$</span> and of the dynamics matrix <span>$\tilde{R}$</span>. Since, for tilt estimation, only the former is of interest, one needs to ask if <span>$X^*$</span> is also optimal if one seeks only an estimate of parts of the unknown matrix <span>$Q$</span>. The following lemma states that this is indeed the case.</p><h3 id="The-Partitioned-Estimation-Lemma"><a class="docs-heading-anchor" href="#The-Partitioned-Estimation-Lemma">The Partitioned Estimation Lemma</a><a id="The-Partitioned-Estimation-Lemma-1"></a><a class="docs-heading-anchor-permalink" href="#The-Partitioned-Estimation-Lemma" title="Permalink"></a></h3><p>Let the matrices <span>$Q$</span>, <span>$P$</span>, <span>$N$</span> and <span>$M$</span> be defined as in the full estimation lemma. Furthermore, let <span>$Q = \begin{bmatrix} Q_1 &amp; Q_2 \end{bmatrix}$</span>, with</p><p><span>$\left\{ \begin{array}{l} Q_1 \in \mathbb{R}^{3 \times q} &amp;\\ Q_2 \in \mathbb{R}^{3 \times (4 - q)} \end{array} \right.$</span></p><p>where <span>$1 \leq q \leq 4$</span>. Assuming <span>$P$</span> has full row rank, the (unique) minimizer <span>$Y^* \in \mathbb{R}^{L \times q}$</span> of</p><p><span>$\underset{Y}{min} \ \mathbb{E} \ [|| MY - Q_1 ||_F^2]$</span> subjected to <span>$\mathbb{E} \ [MY] = Q_1$</span>  (Equation 19)</p><p>is <span>$Y^* = X_1^*$</span>, where <span>$X^* = \begin{bmatrix} X_1^* &amp; X_2^* \end{bmatrix}$</span> is the solution of the full estimation lemma.</p><h3 id="The-Proof-of-the-Partitioned-Estimation-Lemma"><a class="docs-heading-anchor" href="#The-Proof-of-the-Partitioned-Estimation-Lemma">The Proof of the Partitioned Estimation Lemma</a><a id="The-Proof-of-the-Partitioned-Estimation-Lemma-1"></a><a class="docs-heading-anchor-permalink" href="#The-Proof-of-the-Partitioned-Estimation-Lemma" title="Permalink"></a></h3><p>It needs to be shown that <span>$Y = X_1^*$</span> satisfies equation (19). First, since <span>$X^* = \begin{bmatrix} X_1^* &amp; X_2^* \end{bmatrix}$</span> satisfies <span>$\mathbb{E} \ [M X] = Q$</span> in equation (12),</p><p><span>$\mathbb{E} \ [ \begin{bmatrix} M X_1^* &amp; M X_2^* \end{bmatrix} ] = \mathbb{E} \ [M X^*] = Q = \begin{bmatrix} Q_1 &amp; Q_2 \end{bmatrix} \longrightarrow$</span></p><p><span>$\left\{ \begin{array}{l} \mathbb{E} \ [M X_1^*] = Q_1 &amp;\\ \mathbb{E} \ [M X_2^*] = Q_2 \end{array} \right.$</span>.</p><p>Then,</p><p><span>$|| M X^* - Q ||_F^2 = || \begin{bmatrix} M X_1^* - Q_1 &amp; M X_2^* - Q_2 \end{bmatrix} ||_F^2 = || M X_1^* - Q_1 ||_F^2 + || M X_2^* - Q_2 ||_F^2$</span></p><p>i.e. <span>$X^*$</span> minimizes both terms in the last expression separately and <span>$X_1^*$</span> thus minimizes <span>$|| M X_1^* - Q_1 ||_F^2$</span> alone.</p><p><span>$\square$</span></p><p>Applying the partitioned estimation lemma with <span>$q = 1$</span> yields the optimal gravity vector estimate <span>$^B\hat{g}(k)$</span> at time <span>$k$</span> given all sensor measurements <span>$M(k)$</span>,</p><p><span>$^{B}\hat{g}(k) = M(k) X_1^*$</span>,  (Equation 20)</p><p>with <span>$X_1^* \in \mathbb{R}^{L \times 1}$</span>. The <em>optimal fusion vector</em> <span>$X_1^*$</span> is static and completely defined by the geometry of the problem (through <span>$P$</span>) and can thus be computed offline.</p><p>Note that the gravity vector estimate in equation (20) is independent of the rigid body dynamics, which are captured in <span>$^O_B\ddot{R}$</span> (and thus in <span>$\tilde{R}$</span>). This can be seen from</p><p><span>$^{B}\hat{g} = M X_1^* = Q P X_1^* + N X_1^*$</span></p><p><span>$= \begin{bmatrix} ^{B}g &amp; \tilde{R} \end{bmatrix} \ U \Sigma V_1^T \ V_1 \Sigma^{-1} U_1^T \ + N X_1^*$</span></p><p><span>$= \begin{bmatrix} ^{B}g &amp; \tilde{R} \end{bmatrix} \ P \ X_1^* \ + N X_1^*$</span></p><p><span>$= \begin{bmatrix} ^{B}g &amp; \tilde{R} \end{bmatrix} \begin{bmatrix} U_1 \\ U_2 \end{bmatrix} U_1^T + N X_1^*$</span></p><p><span>$= \begin{bmatrix} ^{B}g &amp; \tilde{R} \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} + N X_1^* = ^{B}g + N X_1^*$</span>,</p><p>where the SVD of <span>$P$</span> in equation (16) has been used. Clearly, the matrix <span>$\tilde{R}$</span> does not appear in the estimate, i.e. the gravity vector observation is not corrupted by any dynamic terms. As expected, the sensor noise does enter the estimation equation.</p><h3 id="The-Physical-Interpretation-of-the-Full-Row-Rank-Condition"><a class="docs-heading-anchor" href="#The-Physical-Interpretation-of-the-Full-Row-Rank-Condition">The Physical Interpretation of the Full Row Rank Condition</a><a id="The-Physical-Interpretation-of-the-Full-Row-Rank-Condition-1"></a><a class="docs-heading-anchor-permalink" href="#The-Physical-Interpretation-of-the-Full-Row-Rank-Condition" title="Permalink"></a></h3><p>Both in the full estimation lemma and the partitioned estimation lemma, the matrix <span>$P$</span>, which contains the sensor locations on the rigid body, is assumed to have full row rank. In the following, a physical interpretation of this rank condition is given.</p><p>Consider the case where <span>$P$</span> does not have full row rank. Then, there exists a nontrivial linear combination of the rows of <span>$P$</span>,</p><p><span>$\exists \lambda \neq 0 \in \mathbb{R}^4 : \lambda_1 p_x + \lambda_2 p_y + \lambda_3 p_z + \lambda_4 \textbf{1} = 0$</span>,  (Equation 21)</p><p>where <span>$p_x^T, \ p_y^T, \ p_z^T \in \mathbb{R}^{1 \times L}$</span>, denote the last three rows of <span>$P$</span> (the vectors of <span>$x$</span>, <span>$y$</span> and <span>$z$</span>-coordinates of all sensor locations, respectively) and <span>$\textbf{1}^T \in \mathbb{R}^{1 \times L}$</span>, the vector of all ones, is the first row of <span>$P$</span>. Expression (21) is equivalent to</p><p><span>$\exists \lambda \neq 0 \in \mathbb{R}^4 : \forall i = 1, ..., L$</span></p><p><span>$\lambda_1 \ ^{B}p_{i, x} + \lambda_2 \ ^{B}p_{i, y} + \lambda_3 \ ^{B}p_{i, z} = -\lambda_4$</span>  (Equation 22)</p><p>where <span>$^{B}p_{i, x}, \ ^{B}p_{i, y}, \ ^{B}p_{i, z} \in \mathbb{R}$</span> denote the <span>$x$</span>, <span>$y$</span> and <span>$z$</span>-coordinate of the <span>$i$</span>th sensor location in the body frame. Since the equation <span>$\lambda_1 x + \lambda_2 y + \lambda_3 z = -\lambda_4$</span> defines a plane in <span>$(x,y,z)$</span>-space, condition (22) is equivalent to <em>all</em> <span>$L$</span> sensors lying on the same plane. Therefore, the full row rank condition on <span>$P$</span> is satisfied if and only if <em>not</em> all sensors lie on a plane, this also implies that at least four tri-axis accelerometers are required for the proposed method.</p><p>Note that the gravity vector estimate given in the partitioned estimation lemma is optimal under the assumption that <span>$P$</span> has full row rank. These results can be extended and the rank condition on <span>$P$</span> can be relaxed when one only seeks only the gravity vector. For example, one could directly measure gravity with a single tri-axis accelerometer at the pivot, where the dynamic terms do not enter the measurements.However, this is not possible for the balancing unicycle application.</p><h3 id="Tilt-Estimation"><a class="docs-heading-anchor" href="#Tilt-Estimation">Tilt Estimation</a><a id="Tilt-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Tilt-Estimation" title="Permalink"></a></h3><p>With the estimate <span>$^B\hat{g}$</span> of the gravity vector in the body frame, one can use equation (5) to estimate the body rotation, since the direction of the gravity vector in the inertial frame is known. In this project, the attitude of the rigid body is represented by <span>$z$</span>-<span>$y$</span>-<span>$x$</span>-Euler angles (yaw, pitch, roll), i.e. the body frame <span>$\hat{B}$</span> is obtained by rotating the inertial frame <span>$\hat{O}$</span> succesively about its <span>$z$</span>-axis, then the resulting <span>$y$</span>- and <span>$x$</span>-axis,</p><p><span>$^{O}_{B}R = R_z(\alpha) \ R_y(\beta) \ R_x(\gamma)$</span>,  (Equation 23)</p><p><span>$\left\{ \begin{array}{l} R_z(\alpha) := \begin{bmatrix} cos(\alpha) &amp; -sin(\alpha) &amp; 0 \\ sin(\alpha) &amp; cos(\alpha) &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix} &amp;\\ R_y(\beta) := \begin{bmatrix} cos(\beta) &amp; 0 &amp; sin(\beta) \\ 0 &amp; 1 &amp; 0 \\ -sin(\beta) &amp; 0 &amp; cos(\beta) \end{bmatrix} &amp;\\ R_x(\gamma) := \begin{bmatrix}  1 &amp; 0 &amp; 0 \\ 0 &amp; cos(\gamma) &amp; -sin(\gamma) \\ 0 &amp; sin(\gamma) &amp; cos(\gamma) \end{bmatrix} \end{array} \right.$</span>,</p><p>where <span>$\alpha$</span>, <span>$\beta$</span> and <span>$\gamma$</span> are the yaw, pitch and roll Euler angles, respectively. With this representation, the tilt of the rigid body is captured by <span>$\beta$</span> and <span>$\gamma$</span>. Using equation (23), equation (5) can be written as</p><p><span>$^{B}g = ^{O}_{B}R^T \ ^{O}g = R^T_x(\gamma) \ R^T_y(\beta) \ R^T_z(\alpha) \ ^{O}g$</span>.  (Equation 24)</p><p>Using <span>$^{O}g = \begin{bmatrix} 0 &amp; 0 &amp; g_0 \end{bmatrix}^T$</span> with gravity constant <span>$g_0$</span> and the definitions of the rotation matrices, equation (24) simplifies to</p><p><span>$^{B}g = R^T_x(\gamma) \ R^T_y(\beta) \ ^{O}g = g_0 \begin{bmatrix} -sin(\beta) \\ sin(\gamma) cos(\beta) \\ cos(\gamma) cos(\beta) \end{bmatrix}$</span>.  (Equation 25)</p><p>It follows that the <span>$z$</span>-Euler angle <span>$\alpha$</span> is not observable from the accelerometer measurements.</p><p>Given the estimate of the gravity vector in equation (20), the <em>accelerometric estimates</em> for the <span>$y$</span>- and <span>$x$</span>-Euler angles at time <span>$k$</span> are:</p><p><span>$\left\{ \begin{array}{l} \hat{\beta}_a(k) = atan2(-^{B}\hat{g}_x(k), \sqrt{^{B}\hat{g}_y^2(k) + ^{B}\hat{g}_z^2(k)}) &amp;\\ \hat{\gamma}_a(k) = atan2(^{B}\hat{g}_y(k), ^{B}\hat{g}_z(k)) \end{array} \right.$</span>,  (Equation 26)</p><p>where <span>$atan2$</span> is the four-quadrant inverse tangent. Note that one does not need to know the gravity constant <span>$g_0$</span> for estimating tilt.</p><p>The variance of the angle estimates can be obtained from the variance of the gravity vector estimate, which can in turn be calculated from equation (18) and the SVD of <span>$P$</span> in equation (16).</p><h3 id="The-Application-of-Tilt-Estimation-to-the-Balancing-Unicycle"><a class="docs-heading-anchor" href="#The-Application-of-Tilt-Estimation-to-the-Balancing-Unicycle">The Application of Tilt Estimation to the Balancing Unicycle</a><a id="The-Application-of-Tilt-Estimation-to-the-Balancing-Unicycle-1"></a><a class="docs-heading-anchor-permalink" href="#The-Application-of-Tilt-Estimation-to-the-Balancing-Unicycle" title="Permalink"></a></h3><p>The tilt estimation algorithm is applied to the balancing unicycle robot. The passive structure of the unicycle is balanced on a wheel. There is a reaction wheel that is mounted on top of the rolling wheel, generating torque in the perpendicular direction for keeping the robot in equilibrium. The pitch and roll angles of the robot are estimated from measurements of two inertial measurement units (IMUs) with tri-axis accelerometers and rate gyros using the algorithm presented in the section above. The noise level of the estimate is further reduced by straightforward fusion with data from the rate gyros. Experimental results are provided in the next section.</p><p>The balancing unicycle robot consists of a rigid body in the shape of a rectangular cuboid with two orthogonally attached rotors. The objective is to balance the robot on the bottom wheel. In this configuration, the rigid body has three rotational degrees of freedom, and one translational degree of freedom. One can assume that the robot pivot does not slip due to friction, but rolls freely along a straight line. On the robot chassis, a pair of IMUs are mounted that measure accelerations and angular velocities each along three axes.</p><p>The wheels are actuated by DC motors and rotate relative to the robot structure. When the wheels rotate, they exert inertia reactional and ground reactional forces (by generating angular momenta and towing force) on the robot structure. An absolute encoder is used on each motor to measure the angle of a wheel relative to its mounting axle. Furthermore, the robot carries its own power unit and a computer that is connected to the sensors and the DC motors. The computer is also connected to a WiFi module to broadcast all its local sensor measurements to the terminal of a workstation.</p><p><img src="assets/reactionwheelunicycle/electronics_system.jpeg" alt="electronics_system"/></p><p>A state feedback controller is designed that stabalizes the unstable equilibrium of an upright standing robot. Estimates for the chassis angles are obtained from the tilt estimation algorithm of the section above. Although the details of the controller design are explained in the next section, a brief explanation of the control system follows.</p><p>Foe both wheels, an inner feedback loop is closed for the chassis velocity. The inner-loop controller, which is the critic loop in the Actor/Critic architecture, ensures that velocity commands are tracked at a faster rate than the natural dynamics of the chassis. This way, one can neglect nonlinear effects such as friction and backlash in the actuation mechanism. A linear dynamical model (a linear quadratic regulator) about the equilibrium that takes into account the effect of the inner loop is obtained using a two-timescale technique, where the outer loop updates the actor of the controller. Updating the control policy in the outer-loop results in a stabalizing controller.</p><p>The sensors can generate estimates of all system states: the wheels&#39; angular velocities are calculated using measurements by encoders, estimates of the motors&#39; electrical current rates result from a difference equation using measurements by Hall effect sensors, and estimates of the robot&#39;s pitch and roll angles and their rates and accelerations are derived from the IMU measurements. Note that for balancing, knowledge of yaw is not required. Hence, a centralized full-state feedback LQR controller can be designed for stabalizing the system.</p><h4 id="The-Implemetation-of-the-Tilt-Estimation-Algorithm"><a class="docs-heading-anchor" href="#The-Implemetation-of-the-Tilt-Estimation-Algorithm">The Implemetation of the Tilt Estimation Algorithm</a><a id="The-Implemetation-of-the-Tilt-Estimation-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-Implemetation-of-the-Tilt-Estimation-Algorithm" title="Permalink"></a></h4><p>The coordinate frame definitions and the locations of the two IMUs and the pivot point on the robot&#39;s chassis are indicated in the figure below.</p><p><img src="assets/reactionwheelunicycle/gravity_vector_estimation_lean_back.png" alt="gravity_vector_estimation_lean_back"/></p><p>The position vectors of the sensors are</p><p><span>$^Op_1 = \begin{bmatrix} -0.1400 &amp; -0.0650 &amp; -0.0620 \end{bmatrix}^T$</span> and</p><p><span>$^Op_2 = \begin{bmatrix} -0.0400 &amp; -0.0600 &amp; -0.0600 \end{bmatrix}^T$</span>.</p><p>Also the position of the pivot point in the inertial coordinate frame is</p><p><span>$^Opivot = \begin{bmatrix} -0.097 &amp; -0.1 &amp; -0.032 \end{bmatrix}^T$</span></p><p>With this data, matrix <span>$P$</span> can be constructed as in equation (10).</p><p><span>$P \in \mathbb{R}^{4 \times L}$</span></p><p><span>$L = 2$</span></p><p><span>$P \in \mathbb{R}^{4 \times 2}$</span></p><p><a href="https://github.com/iamazadi/Porta.jl/blob/master/models/development/unicycle.jl">the unicycle graphical dashboard for taking the measurements</a></p><p><span>$^Op_1 = \begin{bmatrix} p_{1x} \\ p_{1y} \\ p_{1z} \end{bmatrix}$</span></p><p><span>$^Op_2 = \begin{bmatrix} p_{2x} \\ p_{2y} \\ p_{2z} \end{bmatrix}$</span></p><p><span>$^Opivot = \begin{bmatrix} pivot_x \\ pivot_y \\ pivot_z \end{bmatrix}$</span></p><p><span>$P = \begin{bmatrix} 1 &amp; 1 \\ p_{1x} - pivot_x &amp; p_{2x} - pivot_x \\ p_{1y} - pivot_y &amp; p_{2y} - pivot_y \\ p_{1z} - pivot_z &amp; p_{2z} - pivot_z \end{bmatrix}$</span></p><p>Applying the partitioned estimation lemma yields the optimal fusion matrix for estimating the gravity vector in the robot&#39;s body frame,</p><p><span>$X = P^T (P P^T)^{-1} \in \mathbb{R}^{L \times 4} \longrightarrow X \in \mathbb{R}^{2 \times 4}$</span>,</p><p><span>$X_1^* = \begin{bmatrix} 0.586913 &amp; -11.3087 &amp; 0.747681 &amp; 0.0 \\ 0.446183 &amp; 8.92749 &amp; -3.54337 &amp; 0.0 \end{bmatrix}$</span>.</p><p>In the implementation of the algorithm, all accelerometer measurements are rotated to the body frame and stacked into the matrix <span>$M(k)$</span> as in equation (8) at each time step. Then, equations (20) and (26) are implemented to obtain the accelerometric estimates for the pitch and roll angles, <span>$\hat{\beta}_a(k)$</span> and <span>$\hat{\gamma}_a(k)$</span>.</p><p>In order to reduce the noise level of the accelerometer-based estimates, a straightforward scheme for data fusion with the tri-axis rate gyro measurements may be used. Let <span>$r(k) \in \mathbb{R}^3$</span> denote the body angular rate at time <span>$k$</span>, which is directly measured by a gyro that is mounted on the body. Thus, an estimate <span>$\hat{r}(k)$</span> of this quantity may be obtained by averaging the measurements of all two gyros. The body rates are transformed to Euler angular rates by</p><p><span>$\begin{bmatrix} \hat{\dot{\alpha}}(k) \\ \hat{\dot{\beta}}(k) \\ \hat{\dot{\gamma}}(k) \end{bmatrix} = \begin{bmatrix} 0 &amp; sin(\hat{\gamma}) / cos(\hat{\beta}) &amp; cos(\hat{\gamma}) / cos(\hat{\beta}) \\ 0 &amp; cos(\hat{\gamma}) &amp; -sin(\hat{\gamma}) \\ 1 &amp; sin(\hat{\gamma}) tan(\hat{\beta}) &amp; cos(\hat{\gamma}) tan(\hat{\beta}) \end{bmatrix} \hat{r}(k)$</span>,  (Equation 27)</p><p>which requires estimates of the Euler angles <span>$\hat{\beta}$</span> and <span>$\hat{\gamma}$</span>. For a straightforward implementation, the most recent estimate may be used as an approximation, i.e. <span>$\hat{\beta} = \hat{\beta}(k - 1)$</span> and <span>$\hat{\gamma} = \hat{\gamma}(k - 1)$</span>.</p><p>Integrating the rate estimates in equation (27) yields estimates for the Euler angles that are based on the rate gyro measurements. Thus, the accelerometer- and gyro-based estimates can be fused to obtain a better overall estimate of the robot pitch and roll angles,</p><p><span>$\left\{ \begin{array}{l} \hat{\beta}(k) = \kappa_1 \hat{\beta}_a(k) + (1 - \kappa_1) (\hat{\beta}(k - 1) + T \hat{\dot{\beta}}(k)) &amp;\\ \hat{\gamma}(k) = \kappa_2 \hat{\gamma}_a(k) + (1 - \kappa_2) (\hat{\gamma}(k - 1) + T \hat{\dot{\gamma}}(k)) \end{array} \right.$</span>,  (Equation 28)</p><p>where <span>$T$</span> is the sampling time (the same as <code>dt</code> in the LQR struct) and <span>$\kappa_1$</span> and <span>$\kappa_2$</span> are tuning parameters that may be chosen such that the variance of the estimate is minimized given the noise specifications of accelerometers and rate gyros. For the application presented in this project, <span>$\kappa_1 = \kappa_2 = 0.01$</span> was used.</p><h4 id="The-Micro-Controller-Program"><a class="docs-heading-anchor" href="#The-Micro-Controller-Program">The Micro-Controller Program</a><a id="The-Micro-Controller-Program-1"></a><a class="docs-heading-anchor-permalink" href="#The-Micro-Controller-Program" title="Permalink"></a></h4><p>The function <code>updateIMU</code> provides the main source of data for the objective of the system. Through this function, the Micro-Controller Unit (MCU) talks to the Inertial Measurement Unit (IMU) modules 1 and 2 for updating the roll and pitch angles along with their first and second derivatives. This is done by calling the function and giving it a pointer to the Linear Quadratic Regulator (LQR) model object. Although both IMUs are used for tilt estimation, the final result is assigned to the field of IMU 1. This function encapsulates matrix-vector multiplications for coordinate transformations, the singular value decomposition for obtaining the gravity vector, and sensor fusion between the tri-axis accelerometers and the tri-axis gyroscopes. Knowing about the position and orientation of each IMU with respect to the body, the function excludes linear accelerations from calculations. So, <code>UpdateIMU</code> gathers the latest inertial measurements form multiple sensor units and computes the roll and pitch angles using known parameters of the system configuration.</p><p><img src="assets/reactionwheelunicycle/schematics/inertialmeasurementunits.jpeg" alt="inertialmeasurementunits"/></p><p>In terms of connectivity, The MCU peripheral USART1 is used to talk to IMU #2 (GY-95T). Set the baudrate of uart1 to 115200 Bits/s for the GY-95 IMU module. Set the Pin6 (PS: IIC/USART output mode selection) of IMU #2 (GY-25T) to zero, in order to use the I2C protocol. The I2C clock speed is set at 100000 Hz in the stanard mode. For saving MCU clock cycles and time, added a DMA request with USART1_RX and DMA2 Stream 2 from peripheral to memory and low priority. The mode is circular and the request call is made once in the main function by passing the usart1 handle and the receive buffer. The request increments the address of memory. The data width is one Byte for both the preipheral and memory.</p><pre><code class="language-c hljs">void updateIMU(LinearQuadraticRegulator *model)
{
  updateIMU1(&amp;(model-&gt;imu1));
  updateIMU2(&amp;(model-&gt;imu2));
  setIndexVec3(&amp;(model-&gt;imu1.R), 0, model-&gt;imu1.accX);
  setIndexVec3(&amp;(model-&gt;imu1.R), 1, model-&gt;imu1.accY);
  setIndexVec3(&amp;(model-&gt;imu1.R), 2, model-&gt;imu1.accZ);
  setIndexVec3(&amp;(model-&gt;imu2.R), 0, model-&gt;imu2.accX);
  setIndexVec3(&amp;(model-&gt;imu2.R), 1, model-&gt;imu2.accY);
  setIndexVec3(&amp;(model-&gt;imu2.R), 2, model-&gt;imu2.accZ);

  for (int i = 0; i &lt; 3; i++)
  {
    setIndexVec3(&amp;(model-&gt;imu1._R), i, 0.0);
    setIndexVec3(&amp;(model-&gt;imu2._R), i, 0.0);
  }

  for (int i = 0; i &lt; 3; i++)
  {
    for (int j = 0; j &lt; 3; j++)
    {
      setIndexVec3(&amp;(model-&gt;imu1._R), i, getIndexVec3(model-&gt;imu1._R, i) + getIndexMat3(model-&gt;imu1.B_A_R, i, j) * getIndexVec3(model-&gt;imu1.R, j));
      setIndexVec3(&amp;(model-&gt;imu2._R), i, getIndexVec3(model-&gt;imu2._R, i) + getIndexMat3(model-&gt;imu2.B_A_R, i, j) * getIndexVec3(model-&gt;imu2.R, j));
    }
  }

  for (int i = 0; i &lt; 3; i++)
  {
    setIndexMat32(&amp;(model-&gt;Matrix), i, 0, getIndexVec3(model-&gt;imu1._R, i));
    setIndexMat32(&amp;(model-&gt;Matrix), i, 1, getIndexVec3(model-&gt;imu2._R, i));
  }

  for (int i = 0; i &lt; 3; i++)
  {
    for (int j = 0; j &lt; 4; j++)
    {
      setIndexMat34(&amp;(model-&gt;Q), i, j, 0.0);
      for (int k = 0; k &lt; 2; k++)
      {
        setIndexMat34(&amp;(model-&gt;Q), i, j, getIndexMat34(model-&gt;Q, i, j) + getIndexMat32(model-&gt;Matrix, i, k) * getIndexMat24(model-&gt;X, k, j));
      }
    }
  }
  setIndexVec3(&amp;(model-&gt;g), 0, getIndexMat34(model-&gt;Q, 0, 0));
  setIndexVec3(&amp;(model-&gt;g), 1, getIndexMat34(model-&gt;Q, 1, 0));
  setIndexVec3(&amp;(model-&gt;g), 2, getIndexMat34(model-&gt;Q, 2, 0));
  model-&gt;beta = atan2(-getIndexVec3(model-&gt;g, 0), sqrt(pow(getIndexVec3(model-&gt;g, 1), 2) + pow(getIndexVec3(model-&gt;g, 2), 2)));
  model-&gt;gamma = atan2(getIndexVec3(model-&gt;g, 1), getIndexVec3(model-&gt;g, 2));

  setIndexVec3(&amp;(model-&gt;imu1.G), 0, model-&gt;imu1.gyrX);
  setIndexVec3(&amp;(model-&gt;imu1.G), 1, model-&gt;imu1.gyrY);
  setIndexVec3(&amp;(model-&gt;imu1.G), 2, model-&gt;imu1.gyrZ);
  setIndexVec3(&amp;(model-&gt;imu2.G), 0, model-&gt;imu2.gyrX);
  setIndexVec3(&amp;(model-&gt;imu2.G), 1, model-&gt;imu2.gyrY);
  setIndexVec3(&amp;(model-&gt;imu2.G), 2, model-&gt;imu2.gyrZ);

  for (int i = 0; i &lt; 3; i++)
  {
    setIndexVec3(&amp;(model-&gt;imu1._G), i, 0.0);
    setIndexVec3(&amp;(model-&gt;imu2._G), i, 0.0);
  }

  for (int i = 0; i &lt; 3; i++)
  {
    for (int j = 0; j &lt; 3; j++)
    {
      setIndexVec3(&amp;(model-&gt;imu1._G), i, getIndexVec3(model-&gt;imu1._G, i) + getIndexMat3(model-&gt;imu1.B_A_R, i, j) * getIndexVec3(model-&gt;imu1.G, j));
      setIndexVec3(&amp;(model-&gt;imu2._G), i, getIndexVec3(model-&gt;imu2._G, i) + getIndexMat3(model-&gt;imu2.B_A_R, i, j) * getIndexVec3(model-&gt;imu2.G, j));
    }
  }
  for (int i = 0; i &lt; 3; i++)
  {
    setIndexVec3(&amp;(model-&gt;r), i, (getIndexVec3(model-&gt;imu1._G, i) + getIndexVec3(model-&gt;imu2._G, i)) / 2.0);
  }

  setIndexMat3(&amp;(model-&gt;E), 0, 0, 0.0);
  setIndexMat3(&amp;(model-&gt;E), 0, 1, sin(model-&gt;gamma) / cos(model-&gt;beta));
  setIndexMat3(&amp;(model-&gt;E), 0, 2, cos(model-&gt;gamma) / cos(model-&gt;beta));
  setIndexMat3(&amp;(model-&gt;E), 1, 0, 0.0);
  setIndexMat3(&amp;(model-&gt;E), 1, 1, cos(model-&gt;gamma));
  setIndexMat3(&amp;(model-&gt;E), 1, 2, -sin(model-&gt;gamma));
  setIndexMat3(&amp;(model-&gt;E), 2, 0, 1.0);
  setIndexMat3(&amp;(model-&gt;E), 2, 1, sin(model-&gt;gamma) * tan(model-&gt;beta));
  setIndexMat3(&amp;(model-&gt;E), 2, 2, cos(model-&gt;gamma) * tan(model-&gt;beta));

  for (int i = 0; i &lt; 3; i++)
  {
    setIndexVec3(&amp;(model-&gt;rDot), i, 0.0);
  }

  for (int i = 0; i &lt; 3; i++)
  {
    for (int j = 0; j &lt; 3; j++)
    {
      setIndexVec3(&amp;(model-&gt;rDot), i, getIndexVec3(model-&gt;rDot, i) + getIndexMat3(model-&gt;E, i, j) * getIndexVec3(model-&gt;r, j));
    }
  }

  model-&gt;fusedBeta = model-&gt;kappa1 * model-&gt;beta + (1.0 - model-&gt;kappa1) * (model-&gt;fusedBeta + model-&gt;dt * (getIndexVec3(model-&gt;rDot, 1) / 180.0 * M_PI));
  model-&gt;fusedGamma = model-&gt;kappa2 * model-&gt;gamma + (1.0 - model-&gt;kappa2) * (model-&gt;fusedGamma + model-&gt;dt * (getIndexVec3(model-&gt;rDot, 2) / 180.0 * M_PI));
  model-&gt;imu1.yaw += model-&gt;dt * getIndexVec3(model-&gt;rDot, 0);

  float _roll = model-&gt;fusedBeta;
  float _pitch = -model-&gt;fusedGamma;
  float _roll_velocity = ((getIndexVec3(model-&gt;rDot, 1) / 180.0 * M_PI) + (_roll - model-&gt;imu1.roll) / model-&gt;dt) / 2.0;
  float _pitch_velocity = ((-getIndexVec3(model-&gt;rDot, 2) / 180.0 * M_PI) + (_pitch - model-&gt;imu1.pitch) / model-&gt;dt) / 2.0;
  model-&gt;imu1.roll_acceleration = _roll_velocity - model-&gt;imu1.roll_velocity;
  model-&gt;imu1.pitch_acceleration = _pitch_velocity - model-&gt;imu1.pitch_velocity;
  model-&gt;imu1.roll_velocity = _roll_velocity;
  model-&gt;imu1.pitch_velocity = _pitch_velocity;
  model-&gt;imu1.roll = _roll;
  model-&gt;imu1.pitch = _pitch;
}</code></pre><h2 id="Stepping-Through-the-Implementation"><a class="docs-heading-anchor" href="#Stepping-Through-the-Implementation">Stepping Through the Implementation</a><a id="Stepping-Through-the-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Stepping-Through-the-Implementation" title="Permalink"></a></h2><p>In this section, we step through the implementation of the robot&#39;s controller in the order of execution. The controller is implemented in the C programming language. It runs on a STM32F401RE mictocontroller, which is clocked at 84 MHz. Starting from first principles, there are at least two loops in a reinforcement learning program: the actor loop and the critic loop. The critic loop operates at a faster timescale and finds filter coefficients by taking actions, making mesurements and computing a recursive algorithm. In contrast, the actor loop is slower and updates the control policy, which is a function that produces actions. Even though actions are taken in the critic loop, the feedback policy function is the same across multiple runs of the loop. The actor loop is where the feedback policy is updated as a function of the latest set of filter coefficients. The state estimations and matrix parameters of the controller are stored in a data structure. The <code>LinearQuadraticRegulator</code> type is instantiated and initialized once, before either of the loops begin execution.</p><pre><code class="language-c hljs">typedef struct
{
  Mat12 W_n;                           // filter matrix
  Mat12 P_n;                           // inverse autocorrelation matrix
  Mat210 K_j;                          // feedback policy
  Vec12 dataset;                       // (xₖ, uₖ)
  Vec12 z_n;                           // z_n in RLS
  Vec12 g_n;                           // g_n in RLS
  Vec12 alpha_n;                       // alpha_n in RLS
  float x_n_dot_z_n;                   // the inner product of the x_n (dataset) and z_n
  int j;                               // step number
  int k;                               // time k
  int n;                               // xₖ ∈ ℝⁿ
  int m;                               // uₖ ∈ ℝᵐ
  float lambda;                        // exponential wighting factor
  float delta;                         // value used to intialize P(0)
  int active;                          // is the model controller active
  float CPUClock;                      // the CPU clock
  float dt;                            // period in seconds
  float reactionDutyCycle;             // reaction wheel&#39;s motor PWM duty cycle
  float rollingDutyCycle;              // rolling wheel&#39;s motor PWM duty cycle
  float reactionDutyCycleChange;       // the maximum incremental change in the reaction motor&#39;s duty cycle
  float rollingDutyCycleChnage;        // the maximum incremental change in the rolling motor&#39;s duty cycle
  float clippingValue;                 // the clipping value for any of the P matrix elements at which the clipping is applied
  float clippingFactor;                // the coefficient by which the P matrix elements are rescaled through scalar multiplication
  float rollSafetyAngle;               // the roll angle in radian beyond which the controller must become deactive for safety
  float pitchSafetyAngle;              // the pitch angle in radian beyond which the controller must become deactive for safety
  float kappa1;                        // tuning parameters to minimize estimate variance (the ratio between the accelerometer and the gyroscope in sensor fusion)
  float kappa2;                        // tuning parameters to minimize estimate variance (the ratio between the accelerometer and the gyroscope in sensor fusion)
  int maxEpisodeLength;                // the maximum number of interactions with the nevironment before the model becomes deactive for safety
  int logPeriod;                       // the period between printing two log messages in terms of control cycles
  int logCounter;                      // the number of control cycles elpased since the last log message printing
  int maxOutOfBounds;                  // the maximum number of consecutive cycles where states are out of the safety bounds
  int outOfBoundsCounter;              // the number of consecutive times when either of safety angles have been detected out of bounds
  float beta;                          // y-Euler angle (pitch)
  float gamma;                         // x-Euler angle (roll)
  float fusedBeta;                     // y-Euler angle (pitch) as the result of fusing the accelerometer sensor measurements with the gyroscope sensor measurements
  float fusedGamma;                    // x-Euler angle (roll) as the result of fusing the accelerometer sensor measurements with the gyroscope sensor measurements
  int noiseQuotient;                   // the quotient of the random number for generating the probing noise
  float noiseScale;                    // the scale of by which the remainder of the probing noise is to be divided
  float time;                          // the time that has elapsed since the start up of the microcontroller in seconds
  float changes;                       // the magnitude of the changes to the filter coefficients after one step forward
  Mat34 Q;                             // The matrix of unknown parameters
  Vec3 r;                              // the average of the body angular rate from rate gyro
  Vec3 rDot;                           // the average of the body angular rate in Euler angles
  Mat3 E;                              // a matrix transfom from body rates to Euler angular rates
  Mat24 X;                             // The optimal fusion matrix
  Mat32 Matrix;                        // all sensor measurements combined
  Vec3 g;                              // The gravity vector
  Mat2 Suu;                            // The input-input kernel
  Mat2 SuuInverse;                     // the inverse of the input-input kernel
  Mat210 Sux;                          // the input-state kernel
  Vec2 u_k;                            // the input vector
  IMU imu1;                            // the first inertial measurement unit
  IMU imu2;                            // the second inertial measurement unit
  Encoder reactionEncoder;             // the reaction wheel encoder
  Encoder rollingEncoder;              // the rolling wheel encoder
  CurrentSensor reactionCurrentSensor; // the reaction wheel&#39;s motor current sensor
  CurrentSensor rollingCurrentSensor;  // the rolling wheel&#39;s motor current sensor
} LinearQuadraticRegulator;</code></pre><p>There are two fuse bits on the robot for configuration without flashing a program. The first one is connected to the port C of the general purpose input / output, pin 0. The fuse bit is active whenever the connected pin is grounded. The fuse bit deactivates the linear quadratic regulator by clearing the <code>active</code> field as a flag in the model structure. Even though the status of the fuse bit 0 is necessary to activate the model, it is not a sufficient condition. The user must connect the fuse bit and also push a blue push button once on the robot for activating the model. The push button is the same blue button that is found on the NUCLEOF401RE board. These two conditions are chained together for safety reasons. If the model is not active, then the robot must stop moving by calling the function <code>resetActuators</code>.</p><p><img src="assets/reactionwheelunicycle/schematics/buttonsandlights.jpeg" alt="buttonsandlights"/></p><pre><code class="language-c hljs">elapsedTime1 = DWT-&gt;CYCCNT;
if (HAL_GPIO_ReadPin(GPIOC, GPIO_PIN_0) == 0)
{
  if (HAL_GPIO_ReadPin(GPIOC, GPIO_PIN_13) == 0)
  {
    HAL_GPIO_WritePin(GPIOA, GPIO_PIN_5, GPIO_PIN_RESET);
    model.active = 1;
  }
}
else
{
  model.active = 0;
  resetActuators(&amp;model);
}</code></pre><p>When the reaction wheel unicycle falls over, the roll and pitch angles of the chassis with respect to the pivot point exceed ten degrees. It makes sense to disable the actuators after a fall has been detected to both save energy and minimize physical shock to gearboxes. The lower and upper bounds on the roll and pitch angles are combined using the logical &quot;or&quot; operator <code>||</code> with the episode counter so that the model stops running after the maximum number of interactions with the environment, the total steps in an episode. A fall or a certain number of interactions, whichever comes first, must cause the model to deactivate on its own. When the model is deactivated, the green light on the NUCLEOF401RE turns on to signify that the controller is no longer active. The user has four options whenever the green LED lights up:</p><ol><li><p>Pick the robot up and make it stand upright, before pushing the blue push button to run again.</p></li><li><p>Switch the power button on the chassis to condition zero, in order to power off the robot.</p></li><li><p>Connect to the robot WiFi network and execute the following command in the terminal for printing the logs. Print <code>uart6</code> serial messages by executing: <code>nc 192.168.4.1 10000</code></p></li><li><p>Activate the Porta.jl environment in a Julia REPL and then run the linked script for visualizing the logs: <a href="https://github.com/iamazadi/Porta.jl/blob/master/models/unicycle.jl">Unicycle</a></p></li></ol><p>Since the robot is portable and has a feedback loop related to the motion of its body, violating the safety angle bounds does not immediately disable the model. Instead, the <code>outOfBoundsCounter</code> is incremented every time the safety conditions are violated and is decremented otherwise. Then the model is deactivated if the out of bounds counter is greater than <code>maxOutOfBounds</code>. This approach reduces the probability that a discontinous state estimation is able to trigger deactivation.</p><pre><code class="language-c hljs">if (fabs(model.imu1.roll) &gt; model.rollSafetyAngle || fabs(model.imu1.pitch) &gt; model.pitchSafetyAngle || model.j &gt; model.maxEpisodeLength)
{
  model.outOfBoundsCounter = model.outOfBoundsCounter + 1;
}
else
{
  model.outOfBoundsCounter = fmax(0, model.outOfBoundsCounter - 1);
}

if (model.outOfBoundsCounter &gt; model.maxOutOfBounds)
{
  model.active = 0;
  HAL_GPIO_WritePin(GPIOA, GPIO_PIN_5, GPIO_PIN_SET);
}</code></pre><p>The microcontroller is built around a Cortex-M4 with Floating Point Unit (FPU) core, which contains hardware extensions for debugging features. The debug extensions allow the core to be stopped either on a given instruction fetch (breakpoint), or on data access (watchpoint). When stopped, the core&#39;s internal state and the system&#39;s external state may be examined. Once examination is complete, the core and the system may be restored and program execution resumed.</p><p><img src="assets/reactionwheelunicycle/schematics/nucleof401re.jpeg" alt="nucleof401re"/></p><p>The ARM Cortex-M4 with FPU core provides integrated on-chip debug support. One of the debug features is called Data Watchpoint Trigger (DWT). The DWT unit provides a means to give the number of clock cycles. The DWT register <code>CYCCNT</code> counts the number of clock cycles. The period of a control loop is required in the application for integrating the gyroscopic angle rates. If we count the number of clocks twice: one time before the loop begins and one time after the loop ends, then we can find the time period that it takes to complete a control loop. In the beginning, we count the number of clocks by assigning the register value to a local variable called <code>t1</code>.</p><p>At the end of the control loop, where the model has taken one step forward, it is time to count the number of the processor&#39;s clock cycles for a second time for measuring delta <code>t</code>. At this point, by assigning the value of the <code>DWT</code> counter register to the variable <code>t2</code> we can know how many cycles are there between <code>t1</code> and <code>t2</code>. Then divide the difference by the number of Central Processing Unit (CPU) clock cycles per second <code>cpuClock</code> for finding the period of the control loop. The field <code>dt</code> of the model struct saves the control period.</p><p>If the model is set to active, then the controller takes one step forward. The function <code>stepForward</code> takes as argument a pointer to the model, mainly because two of its fields require persistent memory across runs: the filter matrix <code>W_n</code> and the inverse autocorrelation matrix <code>P_n</code>. The system state estimation is done by calling <code>updateSensors</code>. But since we extend the meaning of the value function to the quality function <span>$Q(x, u)$</span>, the states <span>$x_k$</span> are appended by the inputs <span>$u_k$</span>, which in turn are computed by calling <code>computeFeedbackPolicy</code>. The function call <code>applyFeedbackPolicy</code> applies the action of the feedback policy, changing the angular velocity of the motors.</p><p><span>$Q(x, u) = Q(z) = W^T \phi(z)$</span></p><p><span>$x_k \in \mathbb{R^n}, \ u_k \in \mathbb{R^m}$</span></p><p>In the case where the model is active, the critic loop is run for a few times before the policy is updated by calling the <code>updateControlPolicy</code> function. However, when the model in not active, neither the critic loop nor the actor loop are executed. During the inactive mode of operation, the program makes measurements by calling the functions <code>updateSensors</code> and <code>computeFeedbackPolicy</code>, and resets the actuators by calling the function <code>resetActuators</code>.</p><pre><code class="language-c hljs">if (model.active == 1)
{
  t1 = DWT-&gt;CYCCNT;
  updateSensors(&amp;model);
  computeFeedbackPolicy(&amp;model);
  applyFeedbackPolicy(&amp;model);
  stepForward(&amp;model);
  if (fabs(model.changes) &lt; 2.0)
  {
    updateControlPolicy(&amp;model);
  }
  model.logCounter = model.logCounter + 1;
  t2 = DWT-&gt;CYCCNT;
  diff = t2 - t1;
  model.dt = (float)diff / model.CPUClock;
}
else
{
  model.logPeriod = 80;
  t1 = DWT-&gt;CYCCNT;
  resetActuators(&amp;model);
  updateSensors(&amp;model);
  computeFeedbackPolicy(&amp;model);
  model.logCounter = model.logCounter + 1;
  t2 = DWT-&gt;CYCCNT;
  diff = t2 - t1;
  model.dt = (float)diff / model.cpuClock;
}</code></pre><p>In order to monitor the controller and debug issues, we write the logs periodically to the standard input / output console. The variable <code>log_counter</code> is incremented by one every control cycle. Then, the log counter variable <code>logCounter</code> is compared to the constnt <code>logPeriod</code> for finding out if a cycle should be logged. But it is not a sufficient condition for logging, because a second fuse bit is also rquired for permission to log. The second fuse bit is connected to the port C of the general purpose input / output, pin 1. Whenever the fuse bit pin is grounded, it is activated. Once the fuse bit is active, the local transmission flag <code>transmit</code> is set at the relevant control cycle count. The reason for <code>logPeriod</code> is to limit the total number of logs per second, as the Micro-Controller Unit (MCU) is too fast for a continuous report. And the second fuse bit is there to turn off logging for saving time, as log transmission takes time away from the control processes. So by using the logical &quot;and&quot; operator <code>&amp;&amp;</code> we can combine the logging period condition with the logging fuse bit, in order to manage the frequnecy of transmissions.</p><pre><code class="language-c hljs">if (model.logCounter &gt; model.logPeriod &amp;&amp; HAL_GPIO_ReadPin(GPIOC, GPIO_PIN_1) == 0)
{
  transmit = 1;
}</code></pre><p>If the <code>transmit</code> variable is equal to one, then the log counter <code>logCounter</code> is cleard along with the <code>transmit</code> variable, before transmission. The function <code>sprintf</code> is called with a message buffer <code>MSG</code> and a formatted string to populate the buffer with numbers. A log message can be anything, but for finding the matrix of known parameters in tilt estimation, the accelerometrs data must be included. After the message is composed, it is given as an argument to the function <code>HAL_UART_Transmit</code>, which stands for: Hardware Abstraction Layer, Universal Asynchronous Receiver / Transmitter, Transmit. The function also requires a pointer to <code>uart6</code>, which is a micro-controller peripheral for serial communications, and the size of the message buffer, along with a time out delay. Printing and transmitting the log finishes the actor loop. The console on the other side of tranmission should receive a line like this: <code>AX1: -0.01, AY1: 1.03, AZ1: 0.00, | AX2: -0.05, AY2: 0.97, AZ2: -0.04, | roll: 0.03, pitch: -1.59, | encT: 0.46, encB: 4.31, | j: 1038.000000, | x0: -0.02, x1: -0.12, x2: 0.03, x3: -1.22, x4: -0.90, x5: 0.05, x6: 0.09, x7: -0.04, x8: 0.00, x9: -0.01, x10: 0.00, x11: 0.00, | P0: -96.08, P1: 0.27, P2: 2.04, P3: 1.18, P4: 1.36, P5: 0.34, P6: 0.03, P7: 0.77, P8: 0.08, P9: 0.57, P10: 62.48, P11: 62.48, dt: 0.001947</code>.</p><p>You can visualize this example message using the <a href="https://github.com/iamazadi/Porta.jl/blob/master/models/unicycle.jl">Unicycle</a> script. The example includes: the tri-axis acceleromer measurements of IMU 1 and IMU 2, the roll and pitch angles after the primary and secondary sensor fusions, the absolute position of both rotary encoders, and the diagonal entries of the inverse auto-correlation matrix <code>P_n</code>. Different messages can be composed for different use cases, for example printing raw sensor readings for calibrating the zero point and the scale of the accelerometers axes.</p><pre><code class="language-c hljs">if (transmit == 1)
{
  t1 = DWT-&gt;CYCCNT;
  transmit = 0;
  model.logCounter = 0;

  sprintf(MSG,
          &quot;AX1: %0.2f, AY1: %0.2f, AZ1: %0.2f, | AX2: %0.2f, AY2: %0.2f, AZ2: %0.2f, | roll: %0.2f, pitch: %0.2f, | encT: %0.2f, encB: %0.2f, | j: %0.1f, | x0: %0.2f, x1: %0.2f, x2: %0.2f, x3: %0.2f, x4: %0.2f, x5: %0.2f, x6: %0.2f, x7: %0.2f, x8: %0.2f, x9: %0.2f, x10: %0.2f, x11: %0.2f, | P0: %0.2f, P1: %0.2f, P2: %0.2f, P3: %0.2f, P4: %0.2f, P5: %0.2f, P6: %0.2f, P7: %0.2f, P8: %0.2f, P9: %0.2f, P10: %0.2f, P11: %0.2f, dt: %0.6f\r\n&quot;,
          model.imu1.accX, model.imu1.accY, model.imu1.accZ, model.imu2.accX, model.imu2.accY, model.imu2.accZ, model.imu1.roll, model.imu1.pitch, model.reactionEncoder.radianAngle, model.rollingEncoder.radianAngle, (float)model.j, model.dataset.x0, model.dataset.x1, model.dataset.x2, model.dataset.x3, model.dataset.x4, model.dataset.x5, model.dataset.x6, model.dataset.x7, model.dataset.x8, model.dataset.x9, model.dataset.x10, model.dataset.x11, getIndexMat12(model.P_n, 0, 0), getIndexMat12(model.P_n, 1, 1), getIndexMat12(model.P_n, 2, 2), getIndexMat12(model.P_n, 3, 3), getIndexMat12(model.P_n, 4, 4), getIndexMat12(model.P_n, 5, 5), getIndexMat12(model.P_n, 6, 6), getIndexMat12(model.P_n, 7, 7), getIndexMat12(model.P_n, 8, 8), getIndexMat12(model.P_n, 9, 9), getIndexMat12(model.P_n, 10, 10), getIndexMat12(model.P_n, 11, 11), model.dt);

  HAL_UART_Transmit(&amp;huart6, MSG, sizeof(MSG), 1000);
  t2 = DWT-&gt;CYCCNT;
  diff = t2 - t1;
  model.dt += (float)diff / model.CPUClock;
}
// Rinse and repeat :)
elapsedTime2 = DWT-&gt;CYCCNT;
elapsedTime = elapsedTime2 - elapsedTime1;
model.time += (float)elapsedTime / model.CPUClock;</code></pre><p>In order to enable the function <code>sprintf</code> to use floating point numbers, do the following steps:</p><ol><li>Open the file <code>gcc-arm-none-eabi.cmake</code> that is created by CubeMX.</li><li>Add the option <code>-u _printf_float</code> to <code>CMAKE_C_FLAGS</code>.</li></ol><p><img src="assets/reactionwheelunicycle/schematics/wifimodule.jpeg" alt="wifimodule"/></p><p><img src="assets/reactionwheelunicycle/hc25_wifi_module.JPG" alt="HC-25 WiFi module"/></p><p>Set the baudrate of <code>uart6</code> to 921600, for the wifi module HC-25. The HC-25 module settings are on the IP address <code>192.168.4.1</code> as a web page. Here is the checklist to set up a new module:</p><ol><li>The password is not set for new modules. So just login without a password to access the settings page.</li><li>Set a username and password for the robot&#39;s access point.</li><li>Set the <em>WiFi Mode</em> to <strong>AP</strong> for Access Point.</li><li>Change the port number from <em>8080</em> to <em>10000</em>.</li><li>Set the <em>Baud Rate</em> parameter to 921600 Bits/s.</li></ol><h2 id="Step-Forward"><a class="docs-heading-anchor" href="#Step-Forward">Step Forward</a><a id="Step-Forward-1"></a><a class="docs-heading-anchor-permalink" href="#Step-Forward" title="Permalink"></a></h2><p>The function <code>stepForward</code> identifies the Q function using RLS with the given pointer to the <code>model</code>. The algorithm updates the Q function at each step. As a result, the filter matrix <code>W_n</code> and the inverse auto-correlation matrix <code>P_n</code> are updated. Performs a one-step update in the parameter vector W by applying RLS to equation.</p><p><span>$W_{j + 1}^T (\phi(z_k) - \gamma \phi(z_{k + 1})) = r(x_k, h_j(x_k))$</span></p><p><span>$W_{j + 1}^T (\phi(z_k) - \phi(z_{k + 1})) = \frac{1}{2} (x_k^T Q x_k + u_k^T R u_k)$</span></p><pre><code class="language-c hljs">void stepForward(LinearQuadraticRegulator *model)</code></pre><p>The vector of filter coefficients <span>$\textbf{w}_n = \begin{bmatrix} w_n(0) &amp; w_n(1) &amp; \ldots &amp; w_n(p) \end{bmatrix}^T$</span> at time <span>$n$</span> minimizes the weighted least squares error. The weighted least squares error is equal to the squared norm of the error at time <span>$i$</span> times an exponential weighting factor, sumed over the observation interval. <span>$\Epsilon (n) = \sum_{i = 0}^{n} \lambda^{n - i} | e(i) |^2$</span>. The exponential weighting (forgetting) factor <span>$\lambda$</span> is greater than zero and, less than or equal to one. <span>$0 &lt; \lambda \leq 1$</span>. The error at time <span>$i$</span> is equal to the difference between the desired signal and the filter output. <span>$e(i) = d(i) - y(i) = d(i) - \textbf{w}_n^T x(i)$</span>. In the definition of the error, <span>$d(i)$</span> is the desired signal at time <span>$i$</span>, and <span>$y(i)$</span> is the filter output at time <span>$i$</span>. The filter output is the result of the matrix-vector product of the filter coefficients and the new data vector. The latest set of filter coefficients <span>$\textbf{w}_n(k)$</span> is used for minimizing the weighted least squares error <span>$\Epsilon (n)$</span>. Also, it is assumed that the weights <span>$\textbf{w}_n$</span> are constant over the observation interval <span>$[0, n]$</span> with end points zero and <span>$n$</span>.</p><p>For the error minimization objective, the partial derivative of the weighted least squares error with respect to the filter coefficients must be equal to zero. Setting the partial derivative equal to zero minimizes the weighted least squares error <span>$\frac{\partial \Epsilon (n)}{\partial \textbf{w}_n^* (k)} = 0$</span> for <span>$k = 0, 1, ..., p$</span>, where <span>$p$</span> denotes the filter order. Following the implications of the partial derivative equation, the filter coefficients are transformed by the exponentially weighted deterministic autocorrelation matrix <span>$\textbf{R}_x(n) \textbf{w}_n = \textbf{r}_{dx}(n)$</span> in order to produce the deterministic cross-correlation between the desired signal <span>$d(n) = \begin{bmatrix} d(n) &amp; d(n - 1) &amp; \ldots &amp; d(0) \end{bmatrix}^T$</span> and the new data vector <span>$\textbf{x}(i) = \begin{bmatrix} x(i) &amp; x(i - 1) &amp; \ldots &amp; x(i - p) \end{bmatrix}^T$</span>.</p><p>Therefore, the deterministic normal equations define the optimum filter coefficients. The exponentially weighted deterministic autocorrelation matrix <span>$\textbf{R}_x(n) \in \mathbb{R}^{(p + 1) \times (p + 1)}$</span> for the new data vector <span>$\textbf{x}(n)$</span> is defined as the sum of the outer product of the data vector with itself, in an exponential way with the given exponential factor <span>$\lambda$</span>. In contrast, the deterministic cross-correlation <span>$\textbf{r}_{dx}(n)$</span> is the outer product between the desired signal <span>$d(n)$</span> and the data vector <span>$\textbf{x}(n)$</span>.</p><p><span>$\left\{ \begin{array}{l} \textbf{r}_{dx}(n) = \sum_{i = 0}^n \lambda^{n - i} d(i) \textbf{x}^*(i) &amp;\\ \textbf{R}_x(n) = \sum_{i = 0}^n \lambda^{n - i} \textbf{x}^*(i) \textbf{x}^T(i) \end{array} \right.$</span></p><p>Multiplying the filter coefficients with the deterministic cross-correlation on the left and then subtracting the result from the weighted norm of the desired signal <span>$|| d(n) ||_\lambda^2$</span> yields the minimum error <span>$\{\Epsilon(n)\}_{min} = || d(n) ||_\lambda^2 - \textbf{r}_{dx}^H(n) \textbf{w}_n$</span>.</p><p>Both the deterministic autocorrelation matrix <span>$\textbf{R}_x(n)$</span> and the deterministic cross-correlation <span>$\textbf{r}_{dx}(n)$</span> depend on the time variable <span>$n$</span>. So instead of directly solving the deterministic normal equations <span>$\textbf{R}_x(n) \textbf{w}_n = \textbf{r}_{dx}(n)$</span>, it is easier to derive a recursive solution for the filter coefficients <span>$\textbf{w}_n$</span>. A correction <span>$\Delta \textbf{w}_{n - 1}$</span> that is applied to the solution at time <span>$n - 1$</span> results in the filter coefficients <span>$\textbf{w}_n = \textbf{w}_{n - 1} + \Delta \textbf{w}_{n - 1}$</span> at time <span>$n$</span>.</p><p>For a recursive equation, first derive the deterministic cross-correlation <span>$\textbf{r}_{dx}(n)$</span> at time <span>$n$</span> in terms of the cross-correlation <span>$\textbf{r}_{dx}(n - 1)$</span> at time <span>$n - 1$</span>. To solve for the filter coefficients, multiply both sides of the deterministic normal equations on the left by the inverse of the deterministic autocorrelation matrix: <span>$\textbf{w}_n = \textbf{R}_x^{-1}(n) \textbf{r}_{dx}(n)$</span>. Second, derive the inverse of the deterministic autocorrelation matrix <span>$\textbf{R}_x^{-1}(n)$</span> in terms of the inverse autocorrelation at the previous time <span>$\textbf{R}_x^{-1}(n - 1)$</span> and the new data vector <span>$\textbf{x}(n)$</span>. On the one hand, the cross-correlation <span>$\textbf{r}_{dx}(n) = \sum_{i = 0}^n \lambda^{n - i} d(i) \textbf{x}^*(i)$</span> may be updated recursively as the sum of the previous cross-correlation times the weighting factor, and the desired signal times new data. On the other hand, the autocorrelation matrix <span>$\textbf{R}_x(n)$</span> may be updated recursively from the autocorrlation of the previous time <span>$\textbf{R}_x(n - 1)$</span> and the new data vector <span>$\textbf{x}(n)$</span> in this way: multiply the previous autocorrelation by the weighting factor and then add the result to the outer product of the new data vector with itself.</p><p><span>$\left\{ \begin{array}{l} \textbf{r}_{dx}(n) = \lambda \textbf{r}_{dx}(n - 1) + d(n) \textbf{x}^*(n) &amp;\\ \textbf{R}_x(n) = \lambda \textbf{R}_x(n - 1) + \textbf{x}^*(n) \textbf{x}^T(n) \end{array} \right.$</span></p><p>Since we are interested in the inverse of the autocorrelation matrix <span>$\textbf{R}_x(n)$</span> we use the Woodbury&#39;s Identity. The Woodbury matrix identity <span>$(\textbf{A} + \textbf{u} \textbf{v}^H)^{-1} = \textbf{A}^{-1} - \frac{\textbf{A}^{-1} \textbf{u} \textbf{v}^H \textbf{A}^{-1}}{1 + \textbf{v}^H \textbf{A}^{-1} \textbf{u}}$</span> says that the inverse of a rank-k correction of some matrix can be computed by doing a rank-k correction to the inverse of the original matrix. Therefore, the multiplication of the weighting factor <span>$\lambda$</span> and the autocorrelation matrix <span>$\textbf{R}_x(n - 1)$</span> at time <span>$n - 1$</span> should be the original matrix <span>$\textbf{A}$</span>, whereas the pair of vectors <span>$\textbf{u}$</span> and <span>$\textbf{v}$</span> in the identity are both equal to the new data vector <span>$\textbf{x}^*(n)$</span>.</p><p><span>$\left\{ \begin{array}{l} \textbf{A} = \lambda \textbf{R}_x(n - 1) &amp;\\ \textbf{u} = \textbf{v} = \textbf{x}^*(n) \end{array} \right.$</span></p><p><span>$\textbf{R}_x^{-1}(n) = \lambda^{-1} \textbf{R}_x^{-1} (n - 1) - \frac{\lambda^{-2} \textbf{R}_x^{-1} (n - 1) \textbf{x}^*(n) \textbf{x}^T(n) \textbf{R}_x^{-1}(n - 1)}{1 + \lambda^{-1} \textbf{x}^T(n) \textbf{R}_x^{-1}(n - 1) \textbf{x}^*(n)}$</span></p><p>Writing the inverse of the deterministic autocorrelation matrix using Woodbury&#39;s identity, <span>$\textbf{P}(n) = \lambda^{-1} [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{x}^T(n) \textbf{P}(n -1)]$</span>, we find that the inverse of the autocorrelation matrix <span>$\textbf{P}(n) = \textbf{R}_x^{-1}(n)$</span> at time <span>$n$</span> involves two terms, one of which is the weighted version of the matrix at time <span>$n - 1$</span>. The other term in the calculation of the inverse matrix is the multiplication of the gain vector and the data vector and the inverse matrix at time <span>$n - 1$</span>. The gain vector is the solution to the equation <span>$\textbf{R}_x(n) \textbf{g}(n) = \textbf{x}^*(n)$</span>. As such, the gain vector <span>$\textbf{g}(n) = \frac{\lambda^{-1} \textbf{P}(n - 1) \textbf{x}^*(n)}{1 + \lambda^{-1} \textbf{x}^T(n) \textbf{P}(n - 1) \textbf{x}^*(n)}$</span> is transformed by the deterministic autocorrelation matrix to yield the new data vector. Alternatively one can say that the new data vector is transformed by the inverse of the deterministic autocorrelation matrix in order to produce the gain vector <span>$\textbf{g}(n) = \textbf{P}(n) \textbf{x}^*(n)$</span>. This is the same as the deterministic normal equations, but the cross-correlation vector <span>$\textbf{r}_{dx}(n)$</span> is replaced with the data vector <span>$\textbf{x}^*(n)$</span>:</p><p><span>$\left\{ \begin{array}{l} \textbf{R}_x(n) \textbf{w}_n = \textbf{r}_{dx}(n) &amp;\\ \textbf{R}_x(n) \textbf{g}(n) = \textbf{x}^*(n) \end{array} \right.$</span></p><pre><code class="language-c hljs">model-&gt;x_n_dot_z_n = 0.0;
float buffer = 0.0;
for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  buffer = getIndexVec12(model-&gt;dataset, i) * getIndexVec12(model-&gt;z_n, i);
  if (isnanf(buffer) == 0)
  {
    model-&gt;x_n_dot_z_n += buffer;
  }
}
if (fabs(model-&gt;lambda + model-&gt;x_n_dot_z_n) &gt; 0)
{
  for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
  {
    setIndexVec12(&amp;(model-&gt;g_n), i, (1.0 / (model-&gt;lambda + model-&gt;x_n_dot_z_n)) * getIndexVec12(model-&gt;z_n, i));
  }
}
else
{
  for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
  {
    setIndexVec12(&amp;(model-&gt;g_n), i, (1.0 / model-&gt;lambda) * getIndexVec12(model-&gt;z_n, i));
  }
}</code></pre><p>The derivation of the time-update equation for the coefficient vector <span>$\textbf{w}_n$</span> completes the recursion. Start with the fact that the transformation of the cross-correlation by the inverse autoccorrelation results in the filter coefficients. Then, replace the cross-correlation with the recursive solution.</p><p><span>$\left\{ \begin{array}{l} \textbf{w}_n = \textbf{P}(n) \textbf{r}_{dx}(n) &amp;\\ \textbf{r}_{dx}(n) = \lambda \textbf{r}_{dx}(n - 1) + d(n) \textbf{x}^*(n) \end{array} \right.$</span></p><p>Replacing the solution with a recursive term gets us half of the way, because in the time-update equation we still need to replace the inverse autocorrelation matrix with a recursive inverse autocorrelation: <span>$\textbf{w}_n = \lambda \textbf{P}(n) \textbf{r}_{dx}(n - 1) + d(n) \textbf{P}(n) \textbf{x}^*(n)$</span>. Recall that the transformation of the data vector by the inverse autocorrelation matrix gives us the gain vector. But we also established that the recursive relation of the inverse autocorrelation matrix includes the gain vector.</p><p><span>$\left\{ \begin{array}{l} \textbf{P}(n) \textbf{x}^*(n) = \textbf{g}(n) &amp;\\ \textbf{P}(n) = \lambda^{-1} [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{x}^T(n) \textbf{P}(n - 1)] \end{array} \right.$</span></p><p>Given these two facts, the time-update of the filter coefficients at time <span>$n$</span> is rewritten, <span>$\textbf{w}_n = [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{x}^T(n) \textbf{P}(n - 1)] \textbf{r}_{dx}(n - 1) + d(n) \textbf{g}(n)$</span>, so that it becomes dependent on the inverse autocorrelation matrix at time <span>$n - 1$</span>. So far, the filter coefficients vector is derived in terms of the following: the filter coefficients at time <span>$n - 1$</span>, the gain vector at time <span>$n$</span>, the desired signal at time <span>$n$</span>, and the new data vector: <span>$\textbf{w}_n = \textbf{w}_{n - 1} + \textbf{g}(n) [d(n) - \textbf{w}_{n - 1}^T \textbf{x}(n)]$</span>. To simplify the time-update equation, we use the filter coefficients at time <span>$n - 1$</span> in place of the transformation of the cross-correlation by the inverse autocorrelation: <span>$\textbf{P}(n - 1) \textbf{r}_{dx}(n - 1) = \textbf{w}_{n - 1}$</span>.</p><pre><code class="language-c hljs">for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  setIndexVec12(&amp;(model-&gt;alpha_n), i, 0.0);
}
for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  for (int j = 0; j &lt; (model-&gt;n + model-&gt;m); j++)
  {
    setIndexVec12(&amp;(model-&gt;alpha_n), i, getIndexVec12(model-&gt;alpha_n, i) + 0.0 - getIndexMat12(model-&gt;W_n, i, j) * getIndexVec12(model-&gt;dataset, j));
  }
}</code></pre><p>Here is yet another simplification for defining the correction to the filter coefficients as the <em>a priori error</em> transforming the gain vector: <span>$\textbf{w}_n = \textbf{w}_{n - 1} + \alpha(n) \textbf{g}(n)$</span>. The <em>a priori error</em> <span>$\alpha(n) = d(n) - \textbf{w}_{n - 1}^T \textbf{x}(n)$</span> is the difference relation between the desired signal <span>$d(n)$</span> at time <span>$n$</span> and the estimate of the desired signal <span>$\textbf{w}_{n - 1}^T \textbf{x}(n)$</span> using the previous set of filter coefficients <span>$\textbf{w}_{n - 1}$</span> at time <span>$n - 1$</span>.</p><p><span>$\left\{ \begin{array}{l} \alpha(n) = d(n) - \textbf{w}_{n - 1}^T \textbf{x}(n) &amp;\\ e(n) = d(n) - \textbf{w}_n^T \textbf{x}(n) \end{array} \right.$</span></p><p>The <em>a priori error</em> <span>$\alpha(n)$</span> is defined as the error that would occur if the filter coefficients were not updated, whereas the <em>a posteriori error</em> <span>$e(n)$</span> is defined as the error that occurs after the weight vector <span>$\textbf{w}_n$</span> is updated.</p><pre><code class="language-c hljs">for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  setIndexVec12(&amp;(model-&gt;z_n), i, 0.0);
}
for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  for (int j = 0; j &lt; (model-&gt;n + model-&gt;m); j++)
  {
    setIndexVec12(&amp;(model-&gt;z_n), i, getIndexVec12(model-&gt;z_n, i) + getIndexMat12(model-&gt;P_n, i, j) * getIndexVec12(model-&gt;dataset, j));
  }
}</code></pre><p>The definition of the filtered information vector <span>$\textbf{z}(n) = \textbf{P}(n - 1) \textbf{x}^*(n)$</span>  makes the equations for the gain vector and the inverse of the deterministic autocorrelation matrix simple.</p><p><span>$\left\{ \begin{array}{l} \textbf{g}(n) = \frac{\lambda^{-1} \textbf{P}(n - 1) \textbf{x}^*(n)}{1 + \lambda^{-1} \textbf{x}^T(n) \textbf{P}(n - 1) \textbf{x}^*(n)} &amp;\\ \textbf{P}(n) = \lambda^{-1} [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{x}^T(n) \textbf{P}(n - 1)] \end{array} \right.$</span></p><p>The filtered information vector <span>$z(n)$</span> at time <span>$n$</span> is the transformation of the new data vector at time <span>$n$</span> by the inverse of the autocorrelation matrix at time <span>$n - 1$</span>.</p><p><span>$\left\{ \begin{array}{l} \textbf{g}(n) = \frac{1}{\lambda + \textbf{x}^T(n) \textbf{z}(n)} \textbf{z}(n) &amp;\\ \textbf{P}(n) = \frac{1}{\lambda} [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{z}^H(n)] \end{array} \right.$</span></p><pre><code class="language-c hljs">for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  for (int j = 0; j &lt; (model-&gt;n + model-&gt;m); j++)
  {
    buffer = getIndexMat12(model-&gt;W_n, i, j) + getIndexVec12(model-&gt;alpha_n, i) * getIndexVec12(model-&gt;g_n, j);
    if (isnanf(buffer) == 0)
    {
      setIndexMat12(&amp;(model-&gt;W_n), i, j, buffer);
    }
  }
}</code></pre><p>In short, we derived five equations for minimizing the weighted least squares error <span>$\Epsilon (n)$</span> in a recursive way: the filtered information vector, the <em>a priori error</em>, the gain vector, the filter coefficients, and the inverse of the autocorrelation matrix. These equations are parts of what is called the exponentially weighted Recursive Least Squares (RLS) algorithm.</p><p><span>$\left\{ \begin{array}{l} \textbf{z}(n) = \textbf{P}(n - 1) \textbf{x}^*(n) &amp;\\ \alpha(n) = d(n) - \textbf{w}_{n - 1}^T \textbf{x}(n) &amp;\\ \textbf{g}(n) = \frac{1}{\lambda + \textbf{x}^T(n) \textbf{z}(n)} \textbf{z}(n) &amp;\\ \textbf{w}_n = \textbf{w}_{n - 1} + \alpha(n) \textbf{g}(n) &amp;\\ \textbf{P}(n) = \frac{1}{\lambda} [\textbf{P}(n - 1) - \textbf{g}(n) \textbf{z}^H(n)] \end{array} \right.$</span></p><pre><code class="language-c hljs">int scaleFlag = 0;
for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
{
  for (int j = 0; j &lt; (model-&gt;n + model-&gt;m); j++)
  {
    buffer = (1.0 / model-&gt;lambda) * (getIndexMat12(model-&gt;P_n, i, j) - getIndexVec12(model-&gt;g_n, i) * getIndexVec12(model-&gt;z_n, j));
    if (isnanf(buffer) == 0)
    {
      if (fabs(buffer) &gt; model-&gt;clippingValue)
      {
        scaleFlag = 1;
      }
      setIndexMat12(&amp;(model-&gt;P_n), i, j, buffer);
    }
  }
}
if (scaleFlag == 1)
{
  for (int i = 0; i &lt; (model-&gt;n + model-&gt;m); i++)
  {
    for (int j = 0; j &lt; (model-&gt;n + model-&gt;m); j++)
    {
      setIndexMat12(&amp;(model-&gt;P_n), i, j, model-&gt;clippingFactor * getIndexMat12(model-&gt;P_n, i, j));
    }
  }
}</code></pre><p>Whenever the weighting factor is equal to one, <span>$\lambda = 1$</span>, the algorithm is called the growing window RLS algorithm, because it has infinite memory of the system&#39;s trajectory. Meaning the algorithm does not forget outliers, even though it can make the effects of older data less significant over time with a forgetting facter <span>$\lambda$</span> less than one. But a sliding window variant of the algorithm can forget outlier at the cost of doubling the computation.</p><p>The recursive updating of the filter coefficients <span>$\textbf{w}_n$</span> and the inverse autocorrelation matrix <span>$\textbf{P}(n)$</span> requires initial conditions for both terms. A suggestion would be to initialize the deterministic autocorrelation matrix with the identity matrix multiplied by a small positive constant <span>$\delta$</span>.</p><p><span>$\left\{ \begin{array}{l} \textbf{R}_x(0) = \delta \textbf{I} &amp;\\ \textbf{P}(0) = \delta^{-1} \textbf{I} &amp;\\ \textbf{w}_0 = \textbf{0} \end{array} \right.$</span></p><p>But setting an initial zero vector for the filter coefficients does not minimize the weighted least squares error <span>$\Epsilon(0)$</span>, and so <span>$\textbf{w}_0$</span> is not an optimal initial vector. However, with an exponential weighting factor less than one, <span>$\lambda &lt; 1$</span>, the bias in the least squares solution goes to zero as <span>$n$</span> increases.</p><p>An adaptive control algorithm based on Q learning that converges to the solution to the discrete-time LQR problem. This is accomplished by solving athe algebraic Riccati equation in real time without knowing the system dynamics by using data measured along the system trajectories.</p><p>Q learning is implemented by repeatedly performing the iterations <span>$W_{j + 1}^T (\phi (z_k) - \gamma \phi (z_{k + 1})) = r (x_k, h_j(x_k))$</span> and <span>$h_{j + 1} (x_k) = \underset{u}{arg \ min} (W_{j + 1}^T \phi (x_k, u))$</span>, for all <span>$x \in X$</span>. In it is seen that the LQR Q function is quadratic in the states and inputs so that <span>$Q(x_k, u_k) = Q(z_k) \equiv (\frac{1}{2}) z_k^T S z_k$</span> where <span>$z_k = \begin{bmatrix} x_k^T &amp;\\ u_k^T \end{bmatrix}$</span>.</p><p>The counter variable <code>k</code> is incremented every time the <code>stepForward</code> function is called for keeping track of the number of steps in an episode. This reminds us of the counter variable <code>j</code>, which counts the number of policy updates in the function <code>updateControlPolicy</code>. In the <code>stepForward</code> function, the variable <code>k</code> is incremented before returning to the <code>main</code> function. Repeat at the next time <code>k + 1</code> and continue until RLS converges and the new parameter vector Wⱼ₊₁ is found.</p><pre><code class="language-c hljs">model-&gt;k = model-&gt;k + 1;</code></pre><h2 id="Update-Control-Policy"><a class="docs-heading-anchor" href="#Update-Control-Policy">Update Control Policy</a><a id="Update-Control-Policy-1"></a><a class="docs-heading-anchor-permalink" href="#Update-Control-Policy" title="Permalink"></a></h2><pre><code class="language-c hljs">void updateControlPolicy(LinearQuadraticRegulator *model)
{
  // unpack the vector Wⱼ₊₁ into the kernel matrix
  // Q(xₖ, uₖ) ≡ 0.5 * transpose([xₖ; uₖ]) * S * [xₖ; uₖ] = 0.5 * transpose([xₖ; uₖ]) * [Sₓₓ Sₓᵤ; Sᵤₓ Sᵤᵤ] * [xₖ; uₖ]
  model-&gt;k = 1;
  model-&gt;j = model-&gt;j + 1;

  for (int i = 0; i &lt; model-&gt;m; i++)
  {
    for (int j = 0; j &lt; model-&gt;n; j++)
    {
      setIndexMat210(&amp;(model-&gt;Sux), i, j, getIndexMat12(model-&gt;W_n, model-&gt;n + i, j));
    }
  }
  for (int i = 0; i &lt; model-&gt;m; i++)
  {
    for (int j = 0; j &lt; model-&gt;m; j++)
    {
      setIndexMat2(&amp;(model-&gt;Suu), i, j, getIndexMat12(model-&gt;W_n, model-&gt;n + i, model-&gt;n + j));
    }
  }

  // Perform the control update using (S24), which is uₖ = -S⁻¹ᵤᵤ * Sᵤₓ * xₖ
  // uₖ = -S⁻¹ᵤᵤ * Sᵤₓ * xₖ
  float determinant = getIndexMat2(model-&gt;Suu, 1, 1) * getIndexMat2(model-&gt;Suu, 2, 2) - getIndexMat2(model-&gt;Suu, 1, 2) * getIndexMat2(model-&gt;Suu, 2, 1);
  // check the rank of S_uu to see if it&#39;s equal to 2 (invertible matrix)
  if (fabs(determinant) &gt; 0.001) // greater than zero
  {
    setIndexMat2(&amp;(model-&gt;SuuInverse), 0, 0, getIndexMat2(model-&gt;Suu, 1, 1) / determinant);
    setIndexMat2(&amp;(model-&gt;SuuInverse), 0, 1, -getIndexMat2(model-&gt;Suu, 0, 1) / determinant);
    setIndexMat2(&amp;(model-&gt;SuuInverse), 1, 0, -getIndexMat2(model-&gt;Suu, 1, 0) / determinant);
    setIndexMat2(&amp;(model-&gt;SuuInverse), 1, 1, getIndexMat2(model-&gt;Suu, 0, 0) / determinant);
    // initialize the gain matrix
    for (int i = 0; i &lt; model-&gt;m; i++)
    {
      for (int j = 0; j &lt; model-&gt;n; j++)
      {
        setIndexMat210(&amp;(model-&gt;K_j), i, j, 0.0);
      }
    }
    for (int i = 0; i &lt; model-&gt;m; i++)
    {
      for (int j = 0; j &lt; model-&gt;n; j++)
      {
        for (int k = 0; k &lt; model-&gt;m; k++)
        {
          setIndexMat210(&amp;(model-&gt;K_j), i, j, getIndexMat210(model-&gt;K_j, i, j) + getIndexMat2(model-&gt;SuuInverse, i, k) * getIndexMat210(model-&gt;Sux, k, j));
        }
      }
    }
  }
  return;
}</code></pre><p><span>$Q(x_k, u_k) = \frac{1}{2} {\begin{bmatrix} x_k \\ u_k \end{bmatrix}}^T S \begin{bmatrix} x_k \\ u_k \end{bmatrix} = \frac{1}{2} {\begin{bmatrix} x_k \\ u_k \end{bmatrix}}^T \begin{bmatrix} S_{xx} &amp; S_{xu} \\ S_{ux} &amp; S_{uu} \end{bmatrix} \begin{bmatrix} x_k \\ u_k \end{bmatrix}$</span></p><h2 id="The-Convergence-of-Selected-Algebraic-Riccati-Equation-Solution-Parameters"><a class="docs-heading-anchor" href="#The-Convergence-of-Selected-Algebraic-Riccati-Equation-Solution-Parameters">The Convergence of Selected Algebraic Riccati Equation Solution Parameters</a><a id="The-Convergence-of-Selected-Algebraic-Riccati-Equation-Solution-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#The-Convergence-of-Selected-Algebraic-Riccati-Equation-Solution-Parameters" title="Permalink"></a></h2><p><img src="assets/reactionwheelunicycle/p_matrix_parameters_a.png" alt="p_matrix_parameters_a"/></p><p>Convergence of selected algebraic Riccati equation solution parameters. The adaptive controller based on value iteration converges to the ARE solution in real time without knowing the system matrix (including the inertia matrix, and the torque and the electromotive force constants of the motors.)</p><p><span>$Q(x_k, u_k) = \frac{1}{2} \begin{bmatrix} x_k \\ u_k \end{bmatrix} \begin{bmatrix} A^T P A + Q &amp; B^T P A \\ A^T P B &amp; B^T P B + R \end{bmatrix} \begin{bmatrix} x_k \\ u_k \end{bmatrix}$</span></p><p><img src="assets/reactionwheelunicycle/p_matrix_parameters_b.png" alt="p_matrix_parameters_b"/></p><h2 id="The-Controllability-of-the-Z-Euler-Angle"><a class="docs-heading-anchor" href="#The-Controllability-of-the-Z-Euler-Angle">The Controllability of the Z-Euler Angle</a><a id="The-Controllability-of-the-Z-Euler-Angle-1"></a><a class="docs-heading-anchor-permalink" href="#The-Controllability-of-the-Z-Euler-Angle" title="Permalink"></a></h2><h2 id="Nonholonomic-Motion-Planning"><a class="docs-heading-anchor" href="#Nonholonomic-Motion-Planning">Nonholonomic Motion Planning</a><a id="Nonholonomic-Motion-Planning-1"></a><a class="docs-heading-anchor-permalink" href="#Nonholonomic-Motion-Planning" title="Permalink"></a></h2><h2 id="Steering-Using-Sinusoids"><a class="docs-heading-anchor" href="#Steering-Using-Sinusoids">Steering Using Sinusoids</a><a id="Steering-Using-Sinusoids-1"></a><a class="docs-heading-anchor-permalink" href="#Steering-Using-Sinusoids" title="Permalink"></a></h2><h2 id="Steering-Second-Order-Canonical-Systems"><a class="docs-heading-anchor" href="#Steering-Second-Order-Canonical-Systems">Steering Second-Order Canonical Systems</a><a id="Steering-Second-Order-Canonical-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Steering-Second-Order-Canonical-Systems" title="Permalink"></a></h2><h2 id="Attitude-Control-of-A-Space-Platform-/-Manipulator-System-Using-Internal-Motion"><a class="docs-heading-anchor" href="#Attitude-Control-of-A-Space-Platform-/-Manipulator-System-Using-Internal-Motion">Attitude Control of A Space Platform / Manipulator System Using Internal Motion</a><a id="Attitude-Control-of-A-Space-Platform-/-Manipulator-System-Using-Internal-Motion-1"></a><a class="docs-heading-anchor-permalink" href="#Attitude-Control-of-A-Space-Platform-/-Manipulator-System-Using-Internal-Motion" title="Permalink"></a></h2><p><img src="assets/reactionwheelunicycle/balance_robot_inverted_pendulum_on_cart.jpeg" alt="balance_robot_inverted_pendulum_on_cart"/></p><p><img src="assets/reactionwheelunicycle/unicycle_modelling_rolling.jpeg" alt="unicycle_modelling_rolling"/></p><p><img src="assets/reactionwheelunicycle/unicycle_modelling_reaction.jpeg" alt="unicycle_modelling_reaction"/></p><p><img src="assets/reactionwheelunicycle/schematics/microcontroller.jpeg" alt="microcontroller"/></p><p><img src="assets/reactionwheelunicycle/schematics/3v3powersupply.jpeg" alt="3v3powersupply"/></p><p><img src="assets/reactionwheelunicycle/schematics/5vpowersupply.jpeg" alt="5vpowersupply"/></p><p>The LQR inputs are bidirectional and analog. The LQR regulates the roll and pitch angles by a choice of a suitable input. There are four digital input pins: <strong>1A</strong>, <strong>2A</strong>, <strong>3A</strong>, <strong>4A</strong>, and a pair of analog enable pins: <strong>1,2En</strong> and <strong>3,4EN</strong>. The enable pins control the speeds of rotation with a 16-bit resolution, whereas the logical input pins: <strong>1A</strong>, <strong>2A</strong>, <strong>3A</strong> and <strong>4A</strong> control the direction of rotation. A motor rotates in reverse by swapping the values of Input 1 with Input 2, switching 2 values in the memory. Therefore, LQR controls the roll and pitch angles by making changes to two variables: <code>rollingPWM</code> corresponding to <strong>1,2EN</strong> and <code>reactionPWM</code> corresponding to <strong>3,4EN</strong>. LQR adds / subtracts from the two variables when it acts in the environment. To drive a direct current actuator, the driver generates an electric potential at the two ends of the actuator&#39;s coil. An electric current in the power terminals (<strong>1Y</strong> and <strong>2Y</strong>, or, <strong>3Y</strong> and <strong>4Y</strong>) occurs whenever the electric potential at the two end points are sufficiently different in intensity. The duty cycle of a PWM signal shapes the line graph of an analog voltage. In a Voltage versus Time graph, the PWM signal is a point on the graph and varies with time. There are two independent PWM signals: the reaction wheel&#39;s motor enable pin and the rolling wheel&#39;s motor enable pin. In turn, the duty cycles of the PWM signals, tell the Integrated Circuit (IC) to adjust the electric potential at the output pins of the IC: <strong>1Y</strong>, <strong>2Y</strong>, <strong>3Y</strong> and <strong>4Y</strong>. Making changes to the duty cycles with the given feedback policy <code>u_k</code>, the registers of channels one and two of Timer 2 are changed after scaling the variables and casting them to integer values.</p><p><img src="assets/reactionwheelunicycle/schematics/motordriver.jpeg" alt="motordriver"/></p><p><img src="assets/reactionwheelunicycle/l293d.JPG" alt="L293D"/></p><p>There is an encoder wheel at the opposite the end of the reaction wheel&#39;s motor. Since the gearbox reduces the speed of rotation of the reaction wheel in exchange for multiplying the output torque, the encoder&#39;s wheel rotates faster than the reaction wheel. The difference in the speed of rotation between the output reaction wheel and the input encoder wheel allows the encoder to be more precise. Also in the motor / encoder assembley, there is an array of small magnets on the circumference of the encoder&#39;s wheel. The resolution of the encoder depends on the number of magnets in the circular array and the gearbox ratio. A Hall effect sensor produces a voltage proportional to an axial component of the magnetic field vector produced by the magnetic array. The encoder measures the absolute position of the wheel using two channels. A pair of Hall effect sensors are mounted near the surface of the encoder&#39;s wheel, such that the magnets pass by the Hall effect sensors. Timer 3 of the MCU is set up to work in encoder mode, with a register of the absolute position of the encoder&#39;s wheel. When Timer 3 is in the encoder mode, it compares the pair of channels at each rising edge of the signals to find the position. Therefore, we call the <code>encodeWheel</code> function with a pointer to the <code>Encoder</code> object of the reaction wheel along with the value of the counter register of Timer 3. The function <code>encodeWheel</code> updates the velocity field of the reaction wheel&#39;s encoder struct to be used in the LQR model as a system state.</p><p><img src="assets/reactionwheelunicycle/schematics/motorb.jpeg" alt="motorb"/></p><p><img src="assets/reactionwheelunicycle/an503.JPG" alt="AN503"/></p><p><img src="assets/reactionwheelunicycle/an503_magnet.JPG" alt="AN503 and a disk magnet"/></p><p>The rolling wheel&#39;s encoder works the same as the reaction wheel&#39;s encoder, except for the fact that the hardware of the channels sensors is photonic rather than magnetic. The rolling wheel encoder&#39;s disk has an alternating pattern of stripes on it for a pair of infrared light emmiting diodes and a pair of photo transistors to sense its rotation. The IR LEDs send light from one side of the wheel to be received by photo transistors on the other side through the alternating pattern. The amount of light received by the photo transistors is translated to two channels of representative electrical signals, which are fed to Timer 4 of the MCU. Supplying the <code>encodeWheel</code> function with a pointer to the rolling wheel&#39;s encoder object and the value of the counter register of Timer 4, the function call updates the wheel velocity. Before connecting the encoder signals to the MCU timer, a voltage division is applied for making sure the amplitudes of the signals do not exceed 3.3 volts.</p><p><img src="assets/reactionwheelunicycle/schematics/motora.jpeg" alt="motora"/></p><p>The <code>senseCurrent</code> function computes the current rates of the reaction and rolling motors. The function accepts two pointers of the <code>CurrentSensor</code> type and updates the <code>currentVelocity</code> field of the respective arguments. Measuring the electric current rate is the result of two Analog to Digital Conversion (ADC) channels, as peripherals of the MCU (pins <code>PC4</code> and <code>PA4</code> of the ADC unit). A pair of Hall effect sensors are powered using a regulated 5-Volt direct current source. To measure the current rate of the driver&#39;s output, two of the wires that connect the driver IC pins (<strong>1Y</strong> and <strong>4Y</strong>) to the respective motor coils (<strong>MotorA2</strong> and <strong>MotorB2</strong>), are routed in such a way that they pass by the respective current sensing Hall effect sensors. When the IC drives a voltage across the motor terminals (<strong>MA1</strong> and <strong>MA2</strong>, or <strong>MB1</strong> and <strong>MB2</strong>), the Hall effect sensors measure the magnetic field vector that is caused by the electric field inside the wires between the motors and the driver. The ratio-metric readings from the magnetic field vectors represent the flows of the electric current of the reaction motor&#39;s and the rolling motor&#39;s coils. The LQR model observes the current rates and regulates them to zero by generating suitable inputs.</p><p><img src="assets/reactionwheelunicycle/schematics/currentsensing.jpeg" alt="currentsensing"/></p><p><img src="assets/reactionwheelunicycle/acs724.JPG" alt="ACS724"/></p><h2 id="Fiber-Optic-Gyroscopes"><a class="docs-heading-anchor" href="#Fiber-Optic-Gyroscopes">Fiber Optic Gyroscopes</a><a id="Fiber-Optic-Gyroscopes-1"></a><a class="docs-heading-anchor-permalink" href="#Fiber-Optic-Gyroscopes" title="Permalink"></a></h2><h2 id="Resources"><a class="docs-heading-anchor" href="#Resources">Resources</a><a id="Resources-1"></a><a class="docs-heading-anchor-permalink" href="#Resources" title="Permalink"></a></h2><ol><li><p>Yohanes Daud, Abdullah Al Mamun and Jian-Xin Xu, <em>Dynamic modeling and characteristics analysis of lateral-pendulum unicycle robot</em>, Robotica (2017) volume 35, pp. 537–568. Cambridge University Press 2015, doi: 10.1017/S0263574715000703.</p></li><li><p>Sebastian Trimpe and Raffaello D’Andrea, <em>Accelerometer-based Tilt Estimation of a Rigid Body with only Rotational Degrees of Freedom</em>, 2010 IEEE International Conference on Robotics and Automation, Anchorage Convention District, May 3-8, 2010, Anchorage, Alaska, USA.</p></li><li><p>K. G. Vamvoudakis, D. Vrabie and F. L. Lewis, &quot;Online adaptive learning of optimal control solutions using integral reinforcement learning,&quot; 2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL), Paris, France, 2011, pp. 250-257, doi: 10.1109/ADPRL.2011.5967359.</p></li><li><p>Y. Engel, S. Mannor, and R. Meir, “The kernel recursive least-squares algorithm,” IEEE Transactions on Signal Processing, vol. 52, no. 8, pp. 2275–2285, 2004.</p></li><li><p>C. Fernandes, L. Gurvits and Z. X. Li, &quot;Attitude control of space platform/manipulator system using internal motion,&quot; Proceedings 1992 IEEE International Conference on Robotics and Automation, Nice, France, 1992, pp. 893-898 vol.1, doi: 10.1109/ROBOT.1992.220183.</p></li><li><p>G. C. Walsh and S. S. Sastry, &quot;On reorienting linked rigid bodies using internal motions,&quot; in IEEE Transactions on Robotics and Automation, vol. 11, no. 1, pp. 139-146, Feb. 1995, doi: 10.1109/70.345946.</p></li><li><p>Hayes, Monson H. (1996). &quot;9.4: Recursive Least Squares&quot;. Statistical Digital Signal Processing and Modeling. Wiley. p. 541. ISBN 0-471-59431-8.</p></li><li><p>Richard M. Murray, Zexiang Li, and S. Shankar Sastry, <em>A Mathematical Introduction to Robotic Manipulation</em>, CRC-Press, March 22, 1994, ISBN 9780849379819, 0849379814.</p></li><li><p>S. Haykin, Adaptive Filter Theory, Prentice-Hall, Englewood-Cliffs, NJ, 1986.</p></li><li><p>Richard S. Sutton and Andrew G. Barto, Reinforcement Learning (An Introduction), second edition, 2018, The MIT Press, Cambridge, Massachusetts, London, England, ISBN: 978-0-262-19398-6.</p></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="newsreport.html">« News Report</a><a class="docs-footer-nextpage" href="multivariablecalculus.html">Multivariable Calculus »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 24 November 2025 12:48">Monday 24 November 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
